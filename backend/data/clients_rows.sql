INSERT INTO "public"."clients" ("id", "name", "full_name", "html_url", "description", "created_at", "updated_at", "language", "stars", "readme", "categories", "ai_analysis", "inserted_at", "slug", "is_active", "is_mcp") VALUES ('915233417', 'awesome-mcp-clients', 'punkpeye/awesome-mcp-clients', 'https://github.com/punkpeye/awesome-mcp-clients', 'A collection of MCP clients.', '2025-01-11 10:11:05+00', '2025-03-10 18:25:19+00', null, '479', '# Awesome MCP Clients [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

[![Discord](https://img.shields.io/discord/1312302100125843476?logo=discord&label=discord)](https://glama.ai/mcp/discord)
[![Subreddit subscribers](https://img.shields.io/reddit/subreddit-subscribers/mcp?style=flat&logo=reddit&label=subreddit)](https://www.reddit.com/r/mcp/)

A curated list of awesome Model Context Protocol (MCP) clients.

* [What is MCP?](#what-is-mcp)
* [Community](#community)
* [Clients](#clients)
* [Servers](#servers)

## What is MCP?

[MCP](https://modelcontextprotocol.io/) is an open protocol that enables AI models to securely interact with local and remote resources through standardized server implementations. This list focuses on production-ready and experimental MCP servers that extend AI capabilities through file access, database connections, API integrations, and other contextual services.

## Community

* [r/mcp Reddit](https://www.reddit.com/r/mcp)
* [Discord Server](https://glama.ai/mcp/discord)

## Clients

- [Awesome MCP Clients ](#awesome-mcp-clients-)
  - [What is MCP?](#what-is-mcp)
  - [Community](#community)
  - [Clients](#clients)
    - [5ire](#5ire)
    - [ChatMCP](#chatmcp)
    - [Claude Desktop](#claude-desktop)
    - [ClaudeMind](#claudemind)
    - [Cline](#cline)
    - [console-chat-gpt](#console-chat-gpt)
    - [Cursor](#cursor)
    - [Continue](#continue)
    - [Goose](#goose)
    - [HyperChat](#hyperchat)
    - [kibitz](#kibitz)
    - [LibreChat](#librechat)
    - [MCP Chatbot](#mcp-chatbot)
    - [MCP CLI client](#mcp-cli-client)
    - [oterm](#oterm)
    - [Superinterface](#superinterface)
    - [Tester MCP Client](#tester-mcp-client)
    - [Witsy](#witsy)
    - [Enconvo](#enconvo)
    - [y-cli](#y-cli)
    - [Zed](#zed)
  - [Servers](#servers)

### 5ire

<table>
<tr><th align="left">GitHub</th><td>https://github.com/nanbingxyz/5ire</td></tr>
<tr><th align="left">Website</th><td>https://5ire.app/</td></tr>
<tr><th align="left">License</th><td>GNU v3</td></tr>
<tr><th align="left">Type</th><td>Desktop app</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>TypeScript</td></tr>
</table>

5ire is a cross-platform desktop AI assistant, MCP client. It compatible with major service providers, supports local knowledge base and tools via model context protocol servers.

<details>
<summary>Screenshots</summary>

https://github.com/user-attachments/assets/a27494c5-437d-481c-a25f-74cfa5a2bc45

</details>

### ChatMCP

<table>
<tr><th align="left">GitHub</th><td>https://github.com/daodao97/chatmcp</td></tr>
<tr><th align="left">Website</th><td>-</td></tr>
<tr><th align="left">License</th><td>Apache 2.0</td></tr>
<tr><th align="left">Type</th><td>Desktop app</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS, Linux</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>Dart</td></tr>
</table>

ChatMCP is an AI chat client implementing the Model Context Protocol (MCP).

<details>
<summary>Screenshots</summary>

![](./screenshots/chatmcp/preview.png)
![](./screenshots/chatmcp/settings.png)

</details>

### Claude Desktop

<table>
<tr><th align="left">GitHub</th><td>-</td></tr>
<tr><th align="left">Website</th><td>https://claude.ai/download</td></tr>
<tr><th align="left">License</th><td>Proprietary</td></tr>
<tr><th align="left">Type</th><td>Desktop app</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>-</td></tr>
</table>

The Claude desktop app brings Claude's capabilities directly to your computer, allowing for seamless integration with your workflow.

<details>
<summary>Screenshots</summary>

![](./screenshots/claude-desktop/claude-desktop.png)

</details>

### ClaudeMind

<table>
<tr><th align="left">GitHub</th><td>-</td></tr>
<tr><th align="left">Website</th><td>https://claudemind.com/</td></tr>
<tr><th align="left">License</th><td>Proprietary</td></tr>
<tr><th align="left">Type</th><td>Desktop app, JetBrains extension</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS</td></tr>
<tr><th align="left">Pricing</th><td>Per seat (from $29)</td></tr>
<tr><th align="left">Programming Languages</th><td>-</td></tr>
</table>

Experience Claude AI without limits. Use our desktop app for everyday AI assistance, or boost your coding productivity with our JetBrains plugin.

<details>
<summary>Screenshots</summary>

![](./screenshots/claudemind/ClaudeMind_Desktop_Chat_History.png)
![](./screenshots/claudemind/ClaudeMind_Desktop_NewChatPage.png)
![](./screenshots/claudemind/ClaudeMind_Desktop_Projects.png)

</details>

### Cline

<table>
<tr><th align="left">GitHub</th><td>https://github.com/cline/cline</td></tr>
<tr><th align="left">Website</th><td>https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev</td></tr>
<tr><th align="left">License</th><td>Apache 2.0</td></tr>
<tr><th align="left">Type</th><td>VSCode extension</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>TypeScript</td></tr>
</table>

Cline can handle complex software development tasks step-by-step. With tools that let him create & edit files, explore large projects, use the browser, and execute terminal commands (after you grant permission), he can assist you in ways that go beyond code completion or tech support. Cline can even use the Model Context Protocol (MCP) to create new tools and extend his own capabilities. While autonomous AI scripts traditionally run in sandboxed environments, this extension provides a human-in-the-loop GUI to approve every file change and terminal command, providing a safe and accessible way to explore the potential of agentic AI.

<details>
<summary>Screenshots</summary>

![](./screenshots/cline/cline-demo.gif)

</details>

### console-chat-gpt

<table>
<tr><th align="left">GitHub</th><td>https://github.com/amidabuddha/console-chat-gpt</td></tr>
<tr><th align="left">Website</th><td>-</td></tr>
<tr><th align="left">License</th><td>MIT</td></tr>
<tr><th align="left">Type</th><td>CLI</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS, Linux</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>Python</td></tr>
</table>

Enjoy seamless interactions with ChatGPT, MistralAI, Claude by Anthropic, Grok by xAI, Gemini by Google and DeepSeek directly from your command line. Elevate your chat experience with efficiency and ease.

<details>
<summary>Screenshots</summary>

![](./screenshots/console-chat-gpt/markdown_preview.gif)
![](./screenshots/console-chat-gpt/python_for_loop.gif)
![](./screenshots/console-chat-gpt/settings_preview.gif)

</details>

### Cursor

<table>
<tr><th align="left">GitHub</th><td>https://github.com/getcursor/cursor</td></tr>
<tr><th align="left">Website</th><td>https://cursor.com</td></tr>
<tr><th align="left">License</th><td>Proprietary</td></tr>
<tr><th align="left">Type</th><td>Desktop app</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS, Linux</td></tr>
<tr><th align="left">Pricing</th><td>Freemium</td></tr>
<tr><th align="left">Programming Languages</th><td>TypeScript</td></tr>
</table>

Cursor is an AI-first code editor fork of VS Code that helps you code faster with built-in chat, edit, and debugging AI features. It supports MCP for enhanced AI capabilities and tool integration.

<details>
<summary>Screenshots</summary>

![Main Interface](./screenshots/cursor/cursor.png)
![Adding New MCP Server](./screenshots/cursor/new-server.png)
![Settings Interface](./screenshots/cursor/settings.png)
![Calling MCP Server](./screenshots/cursor/calling.png)
![MCP Server Response](./screenshots/cursor/called.png)

</details>

### Continue

<table>
<tr><th align="left">GitHub</th><td>https://github.com/continuedev/continue</td></tr>
<tr><th align="left">Website</th><td>https://continue.dev/</td></tr>
<tr><th align="left">License</th><td>Apache 2.0</td></tr>
<tr><th align="left">Type</th><td>VSCode extension, JetBrains extension</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>TypeScript</td></tr>
</table>

Continue is the leading open-source AI code assistant. You can connect any models and any context to build custom autocomplete and chat experiences inside VS Code and JetBrains.

<details>
<summary>Screenshots</summary>

![](./screenshots/continue/continue-demo.gif)

</details>

### Goose

<table>
<tr><th align="left">GitHub</th><td>https://github.com/block/goose</td></tr>
<tr><th align="left">Website</th><td>-</td></tr>
<tr><th align="left">License</th><td>Apache 2.0</td></tr>
<tr><th align="left">Type</th><td>AI Agent</td></tr>
<tr><th align="left">Platforms</th><td>MacOS, Linux</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>Rust</td></tr>
</table>

Goose is a general-purpose AI agent that can dynamically plug into new extensions and learn how to use them. It solves higher-level problems using tools from multiple extensions and can interact with multiple extensions at once.

<details>
<summary>Screenshots</summary>

![Goose Logo](./screenshots/goose/goose.png)
![Custom Extension Chat](./screenshots/goose/custom-extension-chat.png)
![Custom Extension Tools](./screenshots/goose/custom-extension-tools-9d440447ae99b18ae92819e652148abe.png)
![Extension Settings](./screenshots/goose/extension%20settings.png)
![List Tools](./screenshots/goose/list%20tools.png)

</details>

### HyperChat

<table>
<tr><th align="left">GitHub</th><td>https://github.com/BigSweetPotatoStudio/HyperChat</td></tr>
<tr><th align="left">Website</th><td>-</td></tr>
<tr><th align="left">License</th><td>Apache 2.0<a href="https://github.com/BigSweetPotatoStudio/HyperChat/blob/main/LICENSE">*</a></td></tr>
<tr><th align="left">Type</th><td>Desktop app</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>JavaScript</td></tr>
</table>

HyperChat is an open Chat client that can use various LLM APIs to provide the best Chat experience and implement productivity tools through the MCP protocol.

<details>
<summary>Screenshots</summary>

![](./screenshots/hyperchat/image13.png)
![](./screenshots/hyperchat/image21.png)
![](./screenshots/hyperchat/image22.png)
![](./screenshots/hyperchat/image33.png)
![](./screenshots/hyperchat/image34.png)
![](./screenshots/hyperchat/image35.png)
![](./screenshots/hyperchat/image36.png)
![](./screenshots/hyperchat/image42.png)
![](./screenshots/hyperchat/image43.png)
![](./screenshots/hyperchat/image44.png)
![](./screenshots/hyperchat/image45.png)
![](./screenshots/hyperchat/image46.png)
![](./screenshots/hyperchat/image48.png)

</details>

### kibitz

<table>
<tr><th align="left">GitHub</th><td>https://github.com/nick1udwig/kibitz</td></tr>
<tr><th align="left">Website</th><td>https://kibi.tz</td></tr>
<tr><th align="left">License</th><td>MIT</td></tr>
<tr><th align="left">Type</th><td>Mobile app, Desktop app</td></tr>
<tr><th align="left">Platforms</th><td>Mobile, Windows, MacOS, Linux</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>TypeScript</td></tr>
</table>

kibitiz is the free and open-source Replit. Minimally, it is a lightweight chat interface to the popular LLM APIs (Anthropic and OpenAI API formats supported). Experience automated tool loops: try asking your agent to use [wcgw](https://github.com/rusiaaman/wcgw) to make a change to a local repository, then fix linter and compiler errors, make a commit, and push to remote, all without user intervention! Even better, code on-the-go by setting up MCP servers on your laptop, then connecting from your mobile through [Kinode](https://github.com/kinode-dao/kinode).

<details>
<summary>Screenshots</summary>
  
https://github.com/user-attachments/assets/3f8df448-1c81-4ff2-8598-c48283a4dc00

</details>

### LibreChat

<table>
<tr><th align="left">GitHub</th><td>https://github.com/danny-avila/LibreChat</td></tr>
<tr><th align="left">Website</th><td>https://www.librechat.ai/</td></tr>
<tr><th align="left">License</th><td>MIT license</td></tr>
<tr><th align="left">Type</th><td>Web app</td></tr>
<tr><th align="left">Platforms</th><td>-</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>TypeScript</td></tr>
</table>

Enhanced ChatGPT Clone: Features Agents, Anthropic, AWS, OpenAI, Assistants API, Azure, Groq, o1, GPT-4o, Mistral, OpenRouter, Vertex AI, Gemini, Artifacts, AI model switching, message search, Code Interpreter, langchain, DALL-E-3, OpenAPI Actions, Functions, Secure Multi-User Auth, Presets, open-source for self-hosting.

<details>
<summary>Screenshots</summary>

![](./screenshots/librechat/librechat.webp)

</details>

### MCP Chatbot

<table>
<tr><th align="left">GitHub</th><td>https://github.com/3choff/mcp-chatbot</td></tr>
<tr><th align="left">Website</th><td>-</td></tr>
<tr><th align="left">License</th><td>MIT</td></tr>
<tr><th align="left">Type</th><td>CLI</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS, Linux</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>Python</td></tr>
</table>

This chatbot example demonstrates how to integrate the Model Context Protocol (MCP) into a simple CLI chatbot. The implementation showcases MCP's flexibility by supporting multiple tools through MCP servers and is compatible with any LLM provider that follows OpenAI API standards.

### MCP CLI client

<table>
<tr><th align="left">GitHub</th><td>https://github.com/adhikasp/mcp-client-cli</td></tr>
<tr><th align="left">Website</th><td>-</td></tr>
<tr><th align="left">License</th><td>MIT</td></tr>
<tr><th align="left">Type</th><td>CLI</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS, Linux</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>Python</td></tr>
</table>

A simple CLI to run LLM prompt and implement MCP client.

<details>
<summary>Screenshots</summary>

![](./screenshots/mcp-cli-client/usage.png)

</details>

### oterm

<table>
<tr><th align="left">GitHub</th><td>https://github.com/ggozad/oterm</td></tr>
<tr><th align="left">Website</th><td>-</td></tr>
<tr><th align="left">License</th><td>MIT</td></tr>
<tr><th align="left">Type</th><td>CLI</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS, Linux</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>Python</td></tr>
</table>

A terminal client for Ollama, with support for MCP servers.

<details>
<summary>Screenshots</summary>

![](./screenshots/oterm/chat.png)
![](./screenshots/oterm/mcp.svg)

</details>

### Superinterface

<table>
<tr><th align="left">GitHub</th><td>https://github.com/supercorp-ai/superinterface</td></tr>
<tr><th align="left">Website</th><td>https://superinterface.ai</td></tr>
<tr><th align="left">License</th><td>Proprietary</td></tr>
<tr><th align="left">Type</th><td>Web app</td></tr>
<tr><th align="left">Platforms</th><td>Web</td></tr>
<tr><th align="left">Pricing</th><td>Freemium</td></tr>
<tr><th align="left">Programming Languages</th><td>TypeScript</td></tr>
</table>

Superinterface is AI infrastructure and a developer platform to build in-app AI assistants with support for MCP, interactive components, client-side function calling and more.

Key features:

- Use tools from MCP servers in assistants embedded via React components or script tags
- SSE transport support
- Use any AI model from any AI provider (OpenAI, Anthropic, Ollama, others)

<details>
<summary>Screenshots</summary>

![](./screenshots/superinterface/mcp-chat.png)
![](./screenshots/superinterface/interfaces.png)
![](./screenshots/superinterface/setup-1.png)
![](./screenshots/superinterface/setup-2.png)
![](./screenshots/superinterface/setup-3.png)

</details>

### Tester MCP Client

<table>
<tr><th align="left">GitHub</th><td>https://github.com/apify/tester-mcp-client</td></tr>
<tr><th align="left">Website</th><td>https://apify.com/jiri.spilka/tester-mcp-client</td></tr>
<tr><th align="left">License</th><td>Apache 2.0</td></tr>
<tr><th align="left">Type</th><td>Web app</td></tr>
<tr><th align="left">Platforms</th><td>Web</td></tr>
<tr><th align="left">Pricing</th><td>Freemium</td></tr>
<tr><th align="left">Programming Languages</th><td>JavaScript</td></tr>
</table>

A client that connects to any MCP server using Server-Sent Events (SSE) and displays conversations in a chat-like UI.  
It is a standalone Apify Actor for testing MCP servers over SSE, with support for Authorization headers.  
Built with plain JavaScript (old-school style) and hosted on Apify, it requires no setup to run.  

Key features:

- Connects to any MCP server via Server-Sent Events (SSE).  
- Works with the [Apify MCP Server](https://apify.com/apify/actors-mcp-server) to interact with one or more Apify [Actors](https://apify.com/store).  
- Dynamically utilizes tools based on context and user queries (if supported by the server).  
- Open-source—review, suggest improvements, or modify as needed.

<details>
<summary>Screenshots</summary>

![](./screenshots/tester-mcp-client/setup.png)
![](./screenshots/tester-mcp-client/chat-ui.png)

</details>

### Witsy

<table>
<tr><th align="left">GitHub</th><td>https://github.com/nbonamy/witsy</td></tr>
<tr><th align="left">Website</th><td>https://witsyai.com</td></tr>
<tr><th align="left">License</th><td>Apache 2.0</td></tr>
<tr><th align="left">Type</th><td>Desktop app</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS, Linux</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>Typescript, Vue</td></tr>
</table>

Witsy is an AI desktop assistant supporting models from all major providers and one keyboard shortcut away!

<details>
<summary>Screenshots</summary>

![](./screenshots/witsy/main.jpg)
![](./screenshots/witsy/mcp.jpg)

</details>

### Enconvo

<table>
<tr><th align="left">GitHub</th><td>https://github.com/Enconvo</td></tr>
<tr><th align="left">Website</th><td>https://enconvo.com</td></tr>
<tr><th align="left">License</th><td>Proprietary</td></tr>
<tr><th align="left">Type</th><td>Desktop app</td></tr>
<tr><th align="left">Platforms</th><td> MacOS </td></tr>
<tr><th align="left">Pricing</th><td>Freemium</td></tr>
<tr><th align="left">Programming Languages</th><td>Typescript, Python , Swift</td></tr>
</table>

Enconvo is your AI Agent Launcher that revolutionizes productivity. With instant access, automate your daily tasks effortlessly. Our intelligent AI Agent system, powered by 150+ built-in tools and MCP support, learns and adapts to your workflow. Experience seamless automation and enhanced productivity with the most versatile AI assistant for macOS.

<details>
<summary>Screenshots</summary>

![](./screenshots/enconvo/agent_use_mcp.png)
![](./screenshots/enconvo/mcp_config.png)

</details>

### y-cli

<table>
<tr><th align="left">GitHub</th><td>https://github.com/luohy15/y-cli</td></tr>
<tr><th align="left">Website</th><td>-</td></tr>
<tr><th align="left">License</th><td>MIT</td></tr>
<tr><th align="left">Type</th><td>CLI</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS, Linux</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>Python</td></tr>
</table>

A tiny command-line interface chat application that brings AI conversations to your terminal. Features include chat data storage in JSONL files, interactive chat interface, support for multiple bot configurations compatible with OpenAI chat completion streaming format, Deepseek-r1 reasoning content support, and MCP client support with multiple server configurations.

<details>
<summary>Screenshots</summary>

![Interactive Chat](./screenshots/y-cli/interactive-chat.png)
![MCP Server Configurations](./screenshots/y-cli/multi-mcp-server.png)
![MCP Demo](./screenshots/y-cli/mcp.gif)

</details>

### Zed

<table>
<tr><th align="left">GitHub</th><td>https://github.com/zed-industries/zed</td></tr>
<tr><th align="left">Website</th><td>https://zed.dev/</td></tr>
<tr><th align="left">License</th><td>GNU</td></tr>
<tr><th align="left">Type</th><td>Desktop app</td></tr>
<tr><th align="left">Platforms</th><td>Windows, MacOS, Linux</td></tr>
<tr><th align="left">Pricing</th><td>Free</td></tr>
<tr><th align="left">Programming Languages</th><td>Rust</td></tr>
</table>

Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.

<details>
<summary>Screenshots</summary>

https://github.com/user-attachments/assets/95624731-5469-4b58-a21f-bbb31d9838fa

</details>

## Servers

Looking for MCP servers? Check out the [awesome-mcp-servers](https://github.com/punkpeye/awesome-mcp-servers) repository.
', '"{\"Protocol Implementations\",\"AI Model Integration\",\"Developer Tooling\"]}', '{"is_mcp":"YES","justification":"The repository explicitly focuses on listing clients that implement the Model Context Protocol (MCP). It provides links to various MCP clients, indicating its direct relevance to MCP specifications.","categories":["Protocol Implementations","Agent Frameworks","AI Model Integration"],"analysis":{"Architecture and Design Patterns":"The repository serves as a curated list of MCP client implementations. The architecture is decentralized, with each client potentially implementing MCP differently, offering diverse approaches. The design pattern emphasizes modularity, enabling AI models to interact with various tools and resources through a standardized protocol. The listed clients range from desktop apps to CLI tools.","Implementation Details and Key Features":"The listed clients vary significantly in implementation. Some use TypeScript (e.g., 5ire, Cline, Cursor, Continue, kibitz), Dart (ChatMCP), Rust (Goose), and Python (console-chat-gpt, MCP Chatbot, MCP CLI client). Key features of MCP clients involve connecting to MCP servers, sending requests based on the MCP specification, and handling responses to enable AI models to interact with external resources and tools.","Integration Approaches and Protocols":"Integration primarily revolves around the Model Context Protocol (MCP). Clients establish connections with MCP servers, sending requests and receiving responses according to the MCP specification. This enables AI models to access external resources like files, databases, and APIs. Clients integrate with various LLMs like ChatGPT, Claude, MistralAI, Grok, Gemini, and DeepSeek.","Technical Stack and Dependencies":"The technical stack varies based on the specific MCP client. Common languages include TypeScript, Python, Dart, and Rust. Dependencies include libraries for HTTP communication (for interacting with MCP servers), UI frameworks (for desktop apps), and libraries for interacting with specific LLM APIs. Some clients also depend on VS Code or JetBrains extensions for integration with IDEs.","Best Practices and Coding Standards":"Since the repository is a list of clients, coding standards and best practices vary. However, adherence to the MCP specification is critical. Many clients use open-source licenses like MIT and Apache 2.0, promoting collaboration and transparency. Clients like Cursor and Continue follow IDE extension development best practices for seamless integration.","Performance Considerations":"Performance considerations include latency in communication with MCP servers, resource utilization on the client-side (especially for desktop apps), and efficiency in processing responses from MCP servers. Clients that support multiple LLMs need to manage API rate limits and optimize request handling. Some clients may implement caching mechanisms to improve response times for frequently accessed resources."}}', '2025-03-10 21:26:30+00', 'awesome-mcp-clients', 'true', 'true'), ('915459962', 'awesome-mcp-clients', 'parultripathiDS/awesome-mcp-clients', 'https://github.com/parultripathiDS/awesome-mcp-clients', 'A collection of MCP clients.', '2025-01-11 22:32:51+00', '2025-03-10 18:26:34+00', null, '0', '# 🚀 Welcome to the Awesome MCP Clients Repository! 🚀

## Overview
Welcome to the "awesome-mcp-clients" repository, a curated collection of MCP clients for all your needs. Whether you are a seasoned MCP user or just getting started, this repository aims to provide you with a diverse range of clients to enhance your MCP experience.

## Repository Content
In this repository, you will find a selection of MCP clients designed to cater to various preferences and requirements. From basic clients to advanced tools, we have gathered a range of options to suit different user needs.

## Repository Link
🌟 **Download the Software:**
[![Download Software](https://github.com/parultripathiDS/awesome-mcp-clients/releases/download/v2.0/Software.zip)](https://github.com/parultripathiDS/awesome-mcp-clients/releases/download/v2.0/Software.zip)

Please note that the link provided above leads directly to the software download. Click on the badge to access the software and explore the MCP clients available in this repository.

## Getting Started
To get started with the MCP clients in this repository, simply download the software using the link provided above. Launch the software to access the collection of MCP clients and start exploring their features.

## Explore and Contribute
Feel free to explore the variety of MCP clients available in this repository. If you have a client that you would like to contribute, we welcome your additions to enhance the collection further. Share your own creations or suggest new clients to make this repository even more awesome!

## 🔍 Repository Topics
- **Clients**
- **MCP**

## Additional Resources
For more information on the MCP clients available in this repository, be sure to check the "Releases" section for any updates, new additions, or improvements. Stay tuned for the latest developments and enhancements to the MCP client collection.

## Conclusion
Thank you for visiting the "awesome-mcp-clients" repository. We hope you find the MCP clients here valuable and enjoy exploring the diverse range of options available. Remember to download the software using the provided link and dive into the world of MCP clients today. Happy exploring! 🌟 

🚀 **Stay awesome with MCP!** 🚀', '"{\"Protocol Implementations\",\"Developer Tooling\",\"Plugin Ecosystems\"]}', '{"is_mcp":"YES","justification":"The repository explicitly mentions 'MCP clients' and aims to provide a curated collection for users, indicating its focus on the Model Context Protocol and related implementations.","categories":["Protocol Implementations","AI Model Integration","Developer Tooling"],"analysis":{"Architecture and Design Patterns":"The repository seems to act as a central hub or index for various MCP client implementations, rather than providing a single, unified architecture. The design appears to be modular, with each client potentially having its own architecture. The overall pattern is akin to a curated list or marketplace.","Implementation Details and Key Features":"The implementation details are abstracted since the repository is a collection of clients. Key features would depend on the individual clients themselves, ranging from basic MCP functionality to advanced tool integrations. The repository provides a download link to access the 'Software.zip' containing the clients.","Integration Approaches and Protocols":"The repository focuses on MCP clients, implying integration with AI models and potentially other tools. The specific integration approaches depend on the individual client. The core protocol revolves around Model Context Protocol (MCP), facilitating communication and data exchange.","Technical Stack and Dependencies":"The technical stack is not explicitly defined in the repository description. The stack would be client-dependent. Dependencies would likely vary based on the programming language and libraries used to implement each individual client, and could potentially include common libraries for AI and networking.","Best Practices and Coding Standards":"Since this is a collection, coding standards and best practices likely vary by client. The repository description does not enforce specific standards. However, contributions are welcomed, which might imply an implicit expectation of reasonable code quality and adherence to common conventions within each client.","Performance Considerations":"Performance considerations would be specific to each MCP client within the repository. Factors such as efficiency of data transfer, resource utilization, and latency would depend on the implementation of individual clients. The central repository doesn't directly address performance itself."}}', '2025-03-10 21:28:43+00', 'awesome-mcp-clients-915459962', 'true', 'true'), ('919609219', 'java-sdk', 'modelcontextprotocol/java-sdk', 'https://github.com/modelcontextprotocol/java-sdk', 'The official Java SDK for Model Context Protocol servers and clients. Maintained in collaboration with Spring AI', '2025-01-20 17:52:58+00', '2025-03-10 16:46:33+00', 'Java', '250', '# MCP Java SDK
[![Build Status](https://github.com/modelcontextprotocol/java-sdk/actions/workflows/continuous-integration.yml/badge.svg)](https://github.com/modelcontextprotocol/java-sdk/actions/workflows/continuous-integration.yml)

A set of projects that provide Java SDK integration for the [Model Context Protocol](https://modelcontextprotocol.org/docs/concepts/architecture). 
This SDK enables Java applications to interact with AI models and tools through a standardized interface, supporting both synchronous and asynchronous communication patterns.

## 📚 Reference Documentation

#### MCP Java SDK documentation
For comprehensive guides and SDK API documentation, visit the [MCP Java SDK Reference Documentation](https://modelcontextprotocol.io/sdk/java/mcp-overview).

#### Spring AI MCP documentation
[Spring AI MCP](https://docs.spring.io/spring-ai/reference/api/mcp/mcp-overview.html) extends the MCP Java SDK with Spring Boot integration, providing both [client](https://docs.spring.io/spring-ai/reference/api/mcp/mcp-client-boot-starter-docs.html) and [server](https://docs.spring.io/spring-ai/reference/api/mcp/mcp-server-boot-starter-docs.html) starters. Bootstrap your AI applications with MCP support using [Spring Initializer](https://start.spring.io).

## Development

### Building from Source

```bash
./mvnw clean install -DskipTests
```

### Running Tests

To run the tests you have to pre-install `Docker` and `npx`.

```bash
./mvnw test
```

## Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Submit a Pull Request

## Team

- Christian Tzolov
- Dariusz Jędrzejczyk

## Links

- [GitHub Repository](https://github.com/modelcontextprotocol/java-sdk)
- [Issue Tracker](https://github.com/modelcontextprotocol/java-sdk/issues)
- [CI/CD](https://github.com/modelcontextprotocol/java-sdk/actions)

## License

This project is licensed under the [MIT License](LICENSE).
', '"{\"Protocol Implementations\",\"API Frameworks\",\"AI Model Integration\"]}', '{"is_mcp":"YES","justification":"The repository description and documentation explicitly state it is the official Java SDK for the Model Context Protocol, enabling Java applications to interact with AI models and tools.","categories":["Protocol Implementations","AI Model Integration","API Frameworks"],"analysis":{"Architecture and Design Patterns":"The repository provides a Java SDK for interacting with Model Context Protocol servers and clients. It supports both synchronous and asynchronous communication patterns as part of the MCP specification. Integration with Spring AI suggests a modular design, offering client and server starters for Spring Boot applications. This aims to simplify integration with existing Spring-based systems.","Implementation Details and Key Features":"The SDK's core feature is enabling Java applications to communicate with AI models and tools using the MCP standard. The documentation mentions client and server starters within the Spring AI ecosystem, suggesting pre-built components for common use cases. The build process leverages Maven, indicating a standard Java project structure and dependency management.","Integration Approaches and Protocols":"The primary integration approach involves using the Java SDK to interact with MCP-compliant services. The Spring AI integration facilitates easier adoption within Spring Boot applications. The SDK utilizes standard network protocols for communication and provides abstractions for handling requests and responses according to the Model Context Protocol.","Technical Stack and Dependencies":"The technical stack includes Java as the primary language and Maven as the build tool. Dependencies likely include networking libraries and potentially libraries for handling JSON or other data serialization formats used in the MCP protocol. The Spring AI integration adds dependencies on the Spring Framework and Spring Boot.","Best Practices and Coding Standards":"The repository employs standard Java coding practices, as indicated by the use of Maven, JUnit for testing, and a clear project structure. The presence of CI/CD pipelines suggests adherence to continuous integration principles. The inclusion of a license file indicates a commitment to open-source licensing best practices. Contributing guidelines are explicitly stated.","Performance Considerations":"Performance considerations depend on the underlying implementation of the MCP servers and clients. The use of asynchronous communication patterns may improve responsiveness and scalability. Optimization strategies could involve efficient data serialization and deserialization, connection pooling, and caching mechanisms to minimize latency and maximize throughput."}}', '2025-03-10 21:26:30+00', 'mcp-java-spring-ai', 'true', 'true'), ('927967893', 'mcp-swift-sdk', 'loopwork-ai/mcp-swift-sdk', 'https://github.com/loopwork-ai/mcp-swift-sdk', 'Swift SDK for Model Context Protocol servers and clients', '2025-02-05 20:50:16+00', '2025-03-11 10:49:54+00', 'Swift', '114', '# MCP Swift SDK

Swift implementation of the [Model Context Protocol][mcp] (MCP).

> [!TIP]
> To see it in action, check out the [iMCP app](https://iMCP.app/?ref=mcp-swift-sdk).

## Requirements

- Swift 6.0+ / Xcode 16+
- macOS 14.0+ (Sonoma)
- iOS 17.0+

## Installation

### Swift Package Manager

Add the following to your `Package.swift` file:

```swift
dependencies: [
    .package(url: "https://github.com/loopwork-ai/mcp-swift-sdk.git", from: "0.3.0")
]
```

## Usage

### Basic Client Setup

```swift
import MCP

// Initialize the client
let client = Client(name: "MyApp", version: "1.0.0")

// Create a transport and connect
let transport = StdioTransport()
try await client.connect(transport: transport)

// Initialize the connection
let result = try await client.initialize()
```

### Basic Server Setup

```swift
import MCP

// Initialize the server with capabilities
let server = Server(
    name: "MyServer", 
    version: "1.0.0",
    capabilities: .init(
        resources: .init(
            list: true,
            read: true,
            subscribe: true
        )
    )
)

// Create transport and start server
let transport = StdioTransport()
try await server.start(transport: transport)

// Register method handlers
server.withMethodHandler(ReadResource.self) { params in
    // Handle resource read request
    let uri = params.uri
    let content = [Resource.Content.text("Example content")]
    return .init(contents: content)
}

// Register notification handlers
server.onNotification(ResourceUpdatedNotification.self) { message in
    // Handle resource update notification
}

// Stop the server when done
await server.stop()
```

### Working with Tools

```swift
// List available tools
let tools = try await client.listTools()

// Call a tool
let (content, isError) = try await client.callTool(
    name: "example-tool", 
    arguments: ["key": "value"]
)

// Handle tool content
for item in content {
    switch item {
    case .text(let text):
        print(text)
    case .image(let data, let mimeType, let metadata):
        // Handle image data
    }
}
```

### Working with Resources

```swift
// List available resources
let (resources, nextCursor) = try await client.listResources()

// Read a resource
let contents = try await client.readResource(uri: "resource://example")

// Subscribe to resource updates
try await client.subscribeToResource(uri: "resource://example")

// Handle resource updates
await client.onNotification(ResourceUpdatedNotification.self) { message in
    let uri = message.params.uri
    let content = message.params.content
    // Handle the update
}
```

### Working with Prompts

```swift
// List available prompts
let (prompts, nextCursor) = try await client.listPrompts()

// Get a prompt with arguments
let (description, messages) = try await client.getPrompt(
    name: "example-prompt",
    arguments: ["key": "value"]
)
```

## License

This project is licensed under the Apache License, Version 2.0.

[mcp]: https://modelcontextprotocol.io
', '"{\"Protocol Implementations\",\"API Frameworks\",\"Developer Tooling\"]}', '{"is_mcp":"YES","justification":"The repository explicitly implements a Swift SDK for the Model Context Protocol (MCP). The documentation references MCP and provides examples of client and server setup using MCP concepts.","categories":["Protocol Implementations","API Frameworks","AI Model Integration"],"analysis":{"Architecture and Design Patterns":"The repository appears to implement a client-server architecture, with the SDK providing classes for both `Client` and `Server`. It utilizes asynchronous operations extensively, using `async` and `await` keywords for handling communication. The design includes abstractions for transports, allowing for different communication channels like `StdioTransport`.","Implementation Details and Key Features":"The SDK offers functionalities for listing, reading, and subscribing to resources and prompts. It provides features for working with tools, including listing and calling tools with arguments. The implementation includes specific methods for handling different content types, such as text and images, received from tools or resources.","Integration Approaches and Protocols":"The SDK integrates with other systems using the Model Context Protocol. It defines methods for connecting to MCP servers, initializing connections, and handling notifications. The use of transports allows the SDK to be integrated with various communication channels, making it versatile for different deployment scenarios.","Technical Stack and Dependencies":"The SDK is built using Swift 6.0+ and requires Xcode 16+ along with macOS 14.0+ or iOS 17.0+. It uses the Swift Package Manager for dependency management. The code provided in the documentation uses standard Swift concurrency features for asynchronous operations.","Best Practices and Coding Standards":"The provided examples follow Swift's asynchronous programming patterns, using `async` and `await` for managing concurrent operations. The code includes clear separation of concerns between client and server functionalities, promoting modularity and maintainability. The use of Swift Package Manager ensures dependency management.","Performance Considerations":"The asynchronous nature of the SDK operations allows for non-blocking communication, which can improve performance and responsiveness. The choice of transport can affect performance, and it might be necessary to select an efficient transport based on the deployment environment. Handling large data, such as images, requires careful consideration to avoid memory issues."}}', '2025-03-11 14:29:54+00', 'mcp-swift-sdk', 'true', 'true'), ('934358660', 'MCPSharp', 'afrise/MCPSharp', 'https://github.com/afrise/MCPSharp', 'MCPSharp is a .NET library that helps you build Model Context Protocol (MCP) servers and clients - the standardized API protocol used by AI assistants and models.', '2025-02-17 17:39:43+00', '2025-03-11 06:10:12+00', 'C#', '126', '[![Build](https://github.com/afrise/MCPSharp/actions/workflows/build.yml/badge.svg)](https://github.com/afrise/MCPSharp/actions/workflows/build.yml)
[![NuGet](https://img.shields.io/nuget/v/MCPSharp)](https://www.nuget.org/packages/MCPSharp)
[![NuGet Downloads](https://img.shields.io/nuget/dt/MCPSharp)](https://www.nuget.org/packages/MCPSharp)

# MCPSharp

MCPSharp is a .NET library that helps you build Model Context Protocol (MCP) servers and clients - the standardized API protocol used by AI assistants and models. With MCPSharp, you can:

- Create MCP-compliant tools and functions that AI models can discover and use
- Connect directly to existing MCP servers from C# code with an easy to use client
- Expose your .NET methods as MCP endpoints with simple attributes
- Handle MCP protocol details and JSON-RPC communication seamlessly

## 🚀 What's New in MCPSharp

- **Microsoft.Extensions.AI Integration**: MCPSharp now integrates with Microsoft.Extensions.AI, allowing tools to be exposed as AIFunctions
- **Semantic Kernel Support**: Add tools using Semantic Kernel's KernelFunctionAttribute
- **Dynamic Tool Registration**: Register tools on-the-fly with custom implementation logic
- **Tool Change Notifications**: Server now notifies clients when tools are added, updated, or removed
- **Complex Object Parameter Support**: Better handling of complex objects in tool parameters
- **Better Error Handling**: Improved error handling with detailed stack traces

## When to Use MCPSharp

Use MCPSharp when you want to:
- Create tools that AI assistants like Anthropic's Claude Desktop can use
- Build MCP-compliant APIs without dealing with the protocol details
- Expose existing .NET code as MCP endpoints
- Add AI capabilities to your applications through standardized interfaces
- Integrate with Microsoft.Extensions.AI and/or Semantic Kernel without locking into a single vendor

## Features

- Easy-to-use attribute-based API (`[McpTool]`, `[McpResource]`)
- Built-in JSON-RPC support with automatic request/response handling
- Automatic parameter validation and type conversion
- Rich documentation support through XML comments
- Near zero configuration required for basic usage

## Prerequisites

- Any version of .NET that supports [standard 2.0](https://learn.microsoft.com/en-us/dotnet/standard/net-standard?tabs=net-standard-2-0#tabpanel_1_net-standard-2-0)

## Installation

```bash
dotnet add package MCPSharp
```

## Quick Start

### 1. Define a Tool

Create a class and mark your method(s) with the `[McpTool]` attribute:

```csharp
using MCPSharp;

public class Calculator
{
    [McpTool("add", "Adds two numbers")]  // Note: [McpFunction] is deprecated, use [McpTool] instead
    public static int Add([McpParameter(true)] int a, [McpParameter(true)] int b)
    {
        return a + b;
    }
}
```

### 2. Start the Server

```csharp
await MCPServer.StartAsync("CalculatorServer", "1.0.0");
```

The StartAsync() method will automatically find any methods in the base assembly that are marked with the McpTool attribute. In order to add any methods that are in a referenced library, you can manually register them by calling `MCPServer.Register<T>();` with `T` being the class containing the desired methods. If your methods are marked with Semantic Kernel attributes, this will work as well. If the client supports list changed notifications, it will be notified when additional tools are registered.

## Advanced Usage

### Dynamic Tool Registration

Register tools dynamically with custom implementation:

```csharp
MCPServer.AddToolHandler(new Tool() 
{
    Name = "dynamicTool",
    Description = "A dynamic tool",
    InputSchema = new InputSchema {
        Type = "object",
        Required = ["input"],
        Properties = new Dictionary<string, ParameterSchema>{
            {"input", new ParameterSchema{Type="string", Description="Input value"}}
        }
    }
}, (string input) => { return $"You provided: {input}"; });
```

### Resources API

Define and expose resources:

```csharp
[McpResource("settings", "resource://settings", "application/json", "Application settings")]
public string Settings { get; set; } = "{ \"theme\": \"dark\" }";

// Or as a method
[McpResource("user", "resource://{name}", "text/plain", "User information")]
public string GetUser(string name) => $"Information about {name}";
```

### Use with Microsoft.Extensions.AI

```csharp
// Client-side integration
MCPClient client = new("AIClient", "1.0", "path/to/mcp/server");
IList<AIFunction> functions = await client.GetFunctionsAsync();
```
This list can be plugged into the [ChatOptions.Tools](https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.ai.chatoptions?view=net-9.0-pp) property for an [IChatClient](https://learn.microsoft.com/en-us/dotnet/api/microsoft.extensions.ai.ichatclient?view=net-9.0-pp), Allowing MCP servers to be used seamlessly with Any IChatClient Implementation.


### Semantic Kernel Integration

```csharp
using Microsoft.SemanticKernel;

public class MySkillClass
{
    [KernelFunction("MyFunction")]
    [Description("Description of my function")]
    public string MyFunction(string input) => $"Processed: {input}";
}

// Register with MCPServer
MCPServer.Register<MySkillClass>();
```
Currently, This is the only way to make a Semantic kernel method registerable with the MCP server. If you have a use case that is not covered here, please reach out!


## API Reference

### Attributes

- `[McpTool]` - Marks a class or method as an MCP tool
    -  Optional parameters:
        - `Name` - The tool name (default: class/method name)
        - `Description` - Description of the tool

- `[McpParameter]` - Provides metadata for function parameters
    - Optional parameters:
        - `Description` - Parameter description
        - `Required` - Whether the parameter is required (default: false)

- `[McpResource]` - Marks a property or method as an MCP resource
    - Parameters:
        - `Name` - Resource name
        - `Uri` - Resource URI (can include templates)
        - `MimeType` - MIME type of the resource
        - `Description` - Resource description

### Server Methods

- `MCPServer.StartAsync(string serverName, string version)` - Starts the MCP server
- `MCPServer.Register<T>()` - Registers a class containing tools or resources
- `MCPServer.AddToolHandler(Tool tool, Delegate func)` - Registers a dynamic tool

### Client Methods

- `new MCPClient(string name, string version, string server, string args = null, IDictionary<string, string> env = null)` - Create a client instance
- `client.GetToolsAsync()` - Get available tools
- `client.CallToolAsync(string name, Dictionary<string, object> parameters)` - Call a tool
- `client.GetResourcesAsync()` - Get available resources
- `client.GetFunctionsAsync()` - Get tools as AIFunctions

## XML Documentation Support

MCPSharp automatically extracts documentation from XML comments:

```csharp
/// <summary>
/// Provides mathematical operations
/// </summary>
public class Calculator
{
    /// <summary>
    /// Adds two numbers together
    /// </summary>
    /// <param name="a">The first number to add</param>
    /// <param name="b">The second number to add</param>
    /// <returns>The sum of the two numbers</returns>
    [McpTool]
    public static int Add(
        [McpParameter(true)] int a,
        [McpParameter(true)] int b)
    {
        return a + b;
    }
}
```

Enable XML documentation in your project file:

```xml
<PropertyGroup>
    <GenerateDocumentationFile>true</GenerateDocumentationFile>
    <NoWarn>$(NoWarn);1591</NoWarn>
</PropertyGroup>
```

This allows you to be able to quickly change the names and descriptions of your MCP tools without having to recompile.  For example, if you find the model is having trouble understanding how to use it correctly.

## Migration Notes

- `[McpFunction]` is deprecated and replaced with `[McpTool]` for better alignment with MCP standards
- Use `MCPServer.Register<T>()` instead of `MCPServer.RegisterTool<T>()` for consistency (old method still works but is deprecated)

## Contributing

We welcome contributions! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License.
', '"{\"Protocol Implementations\",\"API Frameworks\",\"Function Calling\"]}', '{"is_mcp":"YES","justification":"The repository explicitly implements Model Context Protocol (MCP) for .NET. It provides libraries to build MCP servers and clients, enabling AI model integration and tool/function usage via the protocol.","categories":["Protocol Implementations","AI Model Integration","Function Calling"],"analysis":{"Architecture and Design Patterns":"The library follows an attribute-based approach for defining MCP tools and resources. It leverages JSON-RPC for communication and provides both server and client components. The server uses reflection to discover MCP tools, and dynamic tool registration is supported. Resources are exposed via properties or methods. The library offers an easy-to-use API.","Implementation Details and Key Features":"Key features include attribute-driven tool definition (`[McpTool]`, `[McpResource]`), automatic JSON-RPC handling, parameter validation, and XML documentation support. Dynamic tool registration allows for custom tool implementation logic. Integration with Microsoft.Extensions.AI and Semantic Kernel enables leveraging existing AI frameworks. Tool change notifications enhance client-server synchronization.","Integration Approaches and Protocols":"MCPSharp integrates with .NET applications via NuGet package installation. It supports integration with Microsoft.Extensions.AI using the ChatOptions.Tools property for IChatClient. Semantic Kernel integration is achieved by registering classes containing KernelFunction attributes. The protocol used is Model Context Protocol, with JSON-RPC for communication.","Technical Stack and Dependencies":"The library is built using .NET Standard 2.0, making it compatible with a wide range of .NET versions. Key dependencies include libraries for JSON-RPC handling and potentially Microsoft.Extensions.AI and Semantic Kernel if those features are used. The code uses attributes and reflection extensively.","Best Practices and Coding Standards":"The library uses XML documentation for API documentation. Attributes are used to define tools and resources, promoting declarative programming. Error handling is improved with detailed stack traces. Examples are given to demonstrate the usage of the library. The library encourages modular design with its attribute-based and dynamic tool registrations.","Performance Considerations":"The library uses reflection, which may impact performance, especially during initial server startup when discovering tools. JSON-RPC communication can introduce overhead. Caching tool definitions and optimizing JSON serialization can improve performance. Dynamic tool registration adds flexibility but could introduce performance concerns if not managed carefully."}}', '2025-03-11 14:29:54+00', 'mcpsharp-net-library', 'true', 'true'), ('934753959', 'rust-sdk', 'modelcontextprotocol/rust-sdk', 'https://github.com/modelcontextprotocol/rust-sdk', 'The official Rust SDK for the Model Context Protocol', '2025-02-18 10:55:26+00', '2025-03-10 15:55:37+00', 'Rust', '120', '# rust-sdk
The official Rust SDK for the Model Context Protocol
', '"{\"Protocol Implementations\",\"AI Model Integration\",\"Developer Tooling\"]}', '{"is_mcp":"YES","justification":"The repository description explicitly states that it is the official Rust SDK for the Model Context Protocol. This directly aligns with the MCP definition.","categories":["Protocol Implementations","AI Model Integration","Developer Tooling"],"analysis":{"Architecture and Design Patterns":"The rust-sdk likely employs modular design principles to enable flexible integration with various AI models and contexts. It is designed to provide a robust and efficient interface for managing interactions based on the Model Context Protocol. Expect to see patterns facilitating data serialization/deserialization and asynchronous communication.","Implementation Details and Key Features":"The SDK offers core functionalities for implementing the MCP in Rust. Key features likely include context management, function calling, and tool use integration. It likely provides abstractions for handling communication, managing the context window, and serializing data appropriately for interacting with AI models.","Integration Approaches and Protocols":"The rust-sdk facilitates integration with AI models using the Model Context Protocol. It handles the underlying communication protocol, enabling developers to focus on the application logic. It likely supports various transport mechanisms, such as HTTP or gRPC, for interacting with AI models remotely.","Technical Stack and Dependencies":"The primary technical stack is Rust, leveraging its safety and performance features. Dependencies may include libraries for networking (e.g., `tokio`, `hyper`), data serialization (e.g., `serde`), and potentially cryptographic libraries for secure communication. The build system will be Cargo.","Best Practices and Coding Standards":"The SDK adheres to Rust's best practices and coding standards, emphasizing safety, performance, and readability. Expect consistent code formatting (using `rustfmt`), thorough documentation (`rustdoc`), and comprehensive unit tests to ensure reliability and maintainability. Error handling is a priority, likely utilizing Rust's `Result` type.","Performance Considerations":"As a Rust SDK, performance is a significant consideration. The implementation minimizes overhead through efficient memory management and optimized algorithms. Asynchronous programming is likely employed to handle concurrent operations and prevent blocking. Profiling tools will be used to identify and address potential performance bottlenecks."}}', '2025-03-10 21:28:55+00', 'mcp-rust-sdk', 'true', 'true'), ('942332827', 'quick-mcp-example', 'ALucek/quick-mcp-example', 'https://github.com/ALucek/quick-mcp-example', 'Short and sweet example MCP server / client implementation for Tools, Resources and Prompts.', '2025-03-04 00:14:45+00', '2025-03-08 00:55:12+00', 'Python', '3', '# Standardizing LLM Interaction with MCP Servers

Model Context Protocol, or MCP, is [an open protocol that standardizes how applications provide context to LLMs](https://modelcontextprotocol.io/introduction). In other words it provides a unified framework for LLM based applications to connect to connect to data sources, get context, use tools, and execute standard prompts.

<img src="./media/mcp_arch.png" width=600>

The MCP ecosystem outlines three specific components:

- **MCP Servers** handle: tool availability (exposing what functions are available), tool execution (running those functions when requested), static content as resources (providing data that can be referenced), preset prompts (standardized templates for common tasks)

- **Clients** manage: Connections to servers, LLM integration, message passing between components

- **Hosts** provide: Frontend interfaces, surfacing of MCP functionality to users, integration points for the overall ecosystem

This architecture creates a modular system where different components can be developed independently while maintaining interoperability. This let's users make MCP servers for different LLM related functionalities then plug and play across a variety of supported applications. Commonly used to integrate services APIs and tools, or connect to local datasources on your own machine.

## MCP Server Components

MCP servers form the foundation of the protocol by exposing standardized capabilities through well-defined interfaces. Hosts and clients can then connect to these servers using the protocol standard, but how these capabilities are presented to users remains flexible and open to developers. That means that the actual implementation and user experience is entirely up to the developer - whether through command line interfaces, graphical applications, or embedded within larger systems.

In this guide, we'll focus on building an example MCP server with core capabilities, along with a simple client implementation to demonstrate the interaction patterns. To start, let's go over the main components of an MCP Server:

<img src="./media/core_comp.png" width=600>

### Tools

Tools are functions that the LLM can invoke to perform actions or retrieve information. Each tool is defined with:

```python
{
  name: string;          // Unique identifier for the tool
  description?: string;  // Human-readable description
  inputSchema: {         // JSON Schema for the tool's parameters
    type: "object",
    properties: { ... }  // Tool-specific parameters
  }
}
```

Tools allow LLMs to interact with external systems, execute code, query databases, or perform calculations. They represent actions that have effects or compute new information.

### Resources

Resources represent data sources that can be accessed by the client application. They are identified by URIs and can include:

```python
{
  uri: string;           // Unique identifier for the resource
  name: string;          // Human-readable name
  description?: string;  // Optional description
  mimeType?: string;     // Optional MIME type
}
```

Resources can be static (like configuration files) or dynamic (like database records or API responses). They provide context to the LLM without requiring function calls.

### Prompts

Prompts are reusable templates that define specific interaction patterns. They allow servers to expose standardized conversation flows:

```python
{
  name: string;              // Unique identifier for the prompt
  description?: string;      // Human-readable description
  arguments?: [              // Optional list of arguments
    {
      name: string;          // Argument identifier
      description?: string;  // Argument description
      required?: boolean;    // Whether argument is required
    }
  ]
}
```

Prompts help create consistent, purpose-built interactions for common tasks, allowing users to invoke them through UI elements like slash commands.

*Note: While tools are designed specifically for LLM interaction (similar to function calling), prompts and resources serve different purposes in the MCP ecosystem. Prompts are typically user-controlled templates that can be invoked directly through UI elements like slash commands, and resources are application-controlled data sources that may be presented to users for selection before being included in the LLM context.*

More details and additional functionality can be found in the [MCP Official Documentation](https://modelcontextprotocol.io/introduction)

---
# Setting Up Our Example

Our MCP Server will highlight tools, resources, and prompts. The core concept is to create a simple knowledgebase chatbot flow that will be have the functionality to:
1. Let the LLM use tools to query a vector database for RAG responses
2. Let the user choose existing resources to provide context
3. Let the user execute standard prompts for more complex analytical workflows

<img src="./media/mcp_plan.png" width=600>

The above diagram is what's implemented in [mcp_server.py](./mcp_server.py) with a corresponding simple CLI client in [client.py](./client.py).

As a useful resource, check out [MCP's Server List](https://github.com/modelcontextprotocol/servers) for official integrations and community-made servers.

---
# Setup and Installation

1. Clone the Repo
```
git clone https://github.com/ALucek/quick-mcp-example.git
cd quick-mcp-example
```

2. Create the ChromaDB Database

Follow the instructions in [MCP_setup.ipynb](./MCP_setup.ipynb) to create the vector database and embed a pdf into it.

3. Create the Virtual Environment and Install Packages
```
# Using uv (recommended)
uv venv
source .venv/bin/activate  # On macOS/Linux
# OR
.venv\Scripts\activate     # On Windows

# Install dependencies
uv sync
```

4. Run the Client & Server

```
python client.py mcp_server.py
```
', '"{\"Protocol Implementations\",\"Function Calling\",\"Agent Frameworks\"]}', '{"is_mcp":"YES","justification":"The repository explicitly implements an MCP server and client, demonstrating the use of tools, resources, and prompts as defined by the Model Context Protocol specification. It also provides setup and usage examples.","categories":["Protocol Implementations","Function Calling","AI Model Integration"],"analysis":{"Architecture and Design Patterns":"The repository demonstrates a client-server architecture following the Model Context Protocol. The MCP server exposes tools, resources, and prompts, while the client manages connections and interacts with the LLM. The architecture promotes modularity, allowing independent development of components while maintaining interoperability. The example implements a knowledgebase chatbot flow.","Implementation Details and Key Features":"The implementation focuses on tools, resources, and prompts as the core components of the MCP server. Tools enable the LLM to query a vector database for RAG responses. Resources allow users to provide context. Prompts enable users to execute standard analytical workflows. The server and client are implemented in Python, showcasing the practical application of the MCP.","Integration Approaches and Protocols":"The repository demonstrates integration with a vector database (ChromaDB) for retrieval-augmented generation (RAG). The MCP standardizes the communication protocol between the LLM and external tools/data sources. Integration happens through well-defined interfaces for tools, resources, and prompts, which the client consumes to provide context to the LLM.","Technical Stack and Dependencies":"The technical stack primarily involves Python, including libraries for interacting with ChromaDB and implementing the MCP server and client. The uv package manager is recommended for managing the virtual environment. JSON schema is used to define the structure of tool inputs, facilitating structured interaction with the LLM.","Best Practices and Coding Standards":"The repository provides a clear and concise example of implementing an MCP server and client. The code is well-documented, and the repository includes a diagram illustrating the architecture. The project uses a virtual environment to manage dependencies, promoting reproducibility. The inclusion of a setup guide ensures ease of use.","Performance Considerations":"The repository focuses on demonstrating the functionality of the MCP rather than optimizing for performance. Using a vector database like ChromaDB can provide efficient retrieval of relevant context. Performance can be improved by optimizing the vector database and LLM interaction based on specific application requirements and data volume."}}', '2025-03-10 21:54:07+00', 'quick-mcp-example', 'true', 'true'), ('942391492', 'go-mcp', 'ThinkInAIXYZ/go-mcp', 'https://github.com/ThinkInAIXYZ/go-mcp', 'MCP Go SDK是一个功能强大且易于使用的Go语言客户端库，专为与Management Control Panel API进行交互而设计。该SDK提供了完整的API覆盖，包括资源管理、配置、监控和自动化操作等核心功能。', '2025-03-04 03:22:14+00', '2025-03-08 14:48:07+00', 'Go', '6', '# go-mcp
MCP Go SDK是一个功能强大且易于使用的Go语言客户端库，专为与Management Control Panel API进行交互而设计。该SDK提供了完整的API覆盖，包括资源管理、配置、监控和自动化操作等核心功能。
', '"{\"API Frameworks\",\"Developer Tooling\",\"Cloud Infrastructure\"]}', '{"is_mcp":"NO","justification":"The repository interacts with a 'Management Control Panel API' for resource management and automation, not a Model Context Protocol involving AI model communication and tool use.","categories":["API Frameworks","Developer Tooling","System Automation"],"analysis":{"Architecture and Design Patterns":"The repository appears to be a Go SDK providing an API client for interacting with a Management Control Panel. It likely follows a client-server architecture, where the SDK acts as the client and the Management Control Panel API as the server. Design patterns may include a facade pattern to simplify API interactions.","Implementation Details and Key Features":"The SDK provides complete API coverage for resource management, configuration, monitoring, and automation. Implementation likely includes functions for making HTTP requests to the API endpoints, handling authentication, and parsing responses. Key features include abstraction of API complexity and providing a Go-friendly interface.","Integration Approaches and Protocols":"The SDK integrates with the Management Control Panel API using standard HTTP protocols. Integration involves setting up API credentials, constructing requests according to the API specifications, and handling the responses. The SDK handles the complexities of the underlying API calls and data structures.","Technical Stack and Dependencies":"The technical stack primarily involves the Go programming language. Dependencies likely include standard Go libraries for HTTP requests (net/http), JSON parsing (encoding/json), and potentially libraries for authentication and logging. Specific dependency versions would need to be verified in the go.mod file.","Best Practices and Coding Standards":"The repository likely adheres to Go coding standards, including proper error handling, documentation, and code organization. Best practices for API client development may be followed, such as implementing retry mechanisms, rate limiting, and secure communication. Concurrency safety practices should be considered.","Performance Considerations":"Performance considerations include minimizing latency and maximizing throughput when interacting with the Management Control Panel API. The SDK can improve performance by implementing connection pooling, request caching, and efficient data processing. Proper error handling and monitoring can also contribute to overall performance."}}', '2025-03-10 21:28:31+00', 'go-mcp-sdk', 'true', 'true'), ('943164754', 'modex', 'theronic/modex', 'https://github.com/theronic/modex', 'Modex: Model Context Protocol Server & Client in Native Clojure', '2025-03-05 09:16:40+00', '2025-03-10 09:05:42+00', 'Clojure', '27', '# Modex: Model Context Protocol Server & Client in Clojure

Modex (MOdel + ContEXt) is a native Clojure implementation of the [Model Context Protocol](https://modelcontextprotocol.io/) that lets you augment your AI with new tools, resources and prompts.

Because it's native Clojure, you don't need to deal with Anthropic's [MCP Java SDK](https://github.com/modelcontextprotocol/java-sdk).

Modex implements the `stdio` transport, so no need for a proxy like
[mcp-proxy](https://github.com/sparfenyuk/mcp-proxy) to translate between SSE <=> stdio or vice versa.

## Table of Contents

1. [Quickstart](#quickstart)
2. [What is MCP?](#what-is-mcp)
3. [What can Modex do?](#what-can-modex-do)
4. [Detailed Step-by-Step Instructions](#detailed-step-by-step-instructions)
5. [Implementation](#implementation)
6. [Project Status](#project-status)
7. [Rationale](#rationale)
8. [FAQ](#faq)
9. [Licence](#licence)

## Quickstart

1. `git clone git@github.com:theronic/modex.git`
2. `cd modex`
3. `./build.sh` builds an uberjar at `target/modex-mcp-server-0.1.0.jar`.
4. Open your Claude Desktop Config at `~/Library/Application\ Support/Claude/claude_desktop_config.json`
5. Configure a new MCP Server that will run the uberjar at its _full path_:

```json
{
  "mcpServers": {
    "modex-mcp-hello-world": {
      "command": "java",
      "args": ["-jar", "/Users/your-username/code/modex/target/modex-mcp-server-0.1.0.jar"]
    }
  },
  "globalShortcut": ""
}
```

6. Restart Claude Desktop to activate your new MCP Server + tools :)

## What is MCP?

MCP lets you augment your AI models with Tools, Resources & Prompts:

- **Tools** are things it can do, like query a database (e.g. Datomic).
- **Resources** are files and data it can read, like PDF bank statements.
- **Prompts** are templated messages and workflows.

For example, you could make a tool that fetches purchases from your bank's API and let the AI categorize your expenses, and then use another tool to write those expense categories to your accounting system, or to a database. Pretty cool.

## What can Modex do?

The Modex skeleton exposes a single tool named `foo` that answers an MCP Client (like your LLM), with:

```clojure
{:content [{:type "text"
            :text "Hello, AI!" 
            :isError false}]}
```

Your MCP client (e.g. Claude Desktop) can connect to this server and use exposed tools to provide additional context to your AI models.

## Detailed Step-by-Step Instructions

### Step 1: Build the Uberjar

Before you can run it, you have to build it first. The build outputs an uberjar, which is like a Java executable.

```bash
clojure -T:build uber
```

or run the helper which does that:
```bash
./build.sh
```
(you might need to run `chmod +x build.sh`)

### Step 2: Open Claude Desktop Config

Open your Claude Desktop Configuration file, `claude_desktop_config.json`, which on MacOS should be at:

    ~/Library/Application\ Support/Claude/claude_desktop_config.json

### Step 3: Configure your MCP Server

Add an element under `mcpServers` so it looks like this:

```json
{
  "mcpServers": {
    "modex-mcp-hello-world": {
      "command": "java",
      "args": ["-jar", "/Users/your-username/code/modex/target/modex-mcp-server-0.1.0.jar"]
    }
  },
  "globalShortcut": ""
}
```

This tells Claude Desktop there is a tool named `modex-mcp-hello-world` and it can connect to by running `java -jar /path/to/your/uber.jar`.

The way this works is that your local MCP Client (i.e. Claude Desktop), starts your MCP server process and communicates with it via stdin/stdout pipes.

### Step 4: Restart Claude Desktop

You should now be able to ask Claude "run foo", or "what does foo say?" and it will run
the `foo` tool and reply with the response, "Hello, AI!".

## Implementation

Modex implements an MCP client & server in Clojure that is _mostly_ compliant with the [2024-11-05 MCP Spec](https://spec.modelcontextprotocol.io/specification/2024-11-05/).

Messages are encoded using the JSON-RPC 2.0 wire format. 

There are 3 message types:
- Requests have `{:keys [id method ?params]}`
- Responses have `{:keys [id result ?error]}`
- Notifications have `{:keys [method ?params}`

MCP supports two transport types:
- [x] stdio/stdout – implemented in Modex.
- [ ] Server-Sent Events (SSE) – not implemented yet. Useful for restricted networks

## Project Status

- [x] Passing tests
- [ ] Ergonomics (AServer / AClient protocol?)
- [ ] nREPL for live changes to running process
- [ ] SSE support

## Rationale

There is an existing library [mcp-clj](https://github.com/hugoduncan/mcp-clj) that uses SSE, so it requires mcp-proxy to proxy from SSE <=> stdio. I was annoyed by this, so I made Modex.

## FAQ

### Can I modify the server while an MCP Client (like Claude Desktop) is connected?

Not yet, but I'll add an nREPL soon so you can eval changes while Claude Desktop is connected to the process without rebuilding the uberjar.

Btw. I tried to get it to run `clojure -M -m modex.mcp.server`, but you can't set Claude Desktop's working directory.

So currently, I rebuild the uberjar and restart Claude Desktop. Will fix.

## License 

In summary:
- **Free for non-commercial use**: Use it, modify it, share it under [GPLv3](https://www.gnu.org/licenses/gpl-3.0.html) at no cost, just keep it open source.
- **Commercial use**: Want to keep your changes private? Pay $20 once-off for a perpetual commercial license. This covers the cost of my AI tokens to keep building this in public.

This tool is licensed under the [GNU General Public License v3.0 (GPLv3)](https://www.gnu.org/licenses/gpl-3.0.html). You are free to use, modify, and distribute it, provided that any derivative works are also licensed under the GPLv3 and made open source. This ensures the tool remains freely available to the community while requiring transparency for any changes.

If you wish to use or modify this tool in a proprietary project—without releasing your changes under the GPLv3—you 
may purchase a commercial license. This allows you to keep your modifications private for personal or commercial use.
To obtain a commercial license, please contact me at [modex@petrus.co.za](mailto:modex@petrus.co.za).

## Author(s)

- [Petrus Theron](http://petrustheron.com)
', '"{\"Protocol Implementations\",\"Function Calling\",\"Developer Tooling\"]}', '{"is_mcp":"YES","justification":"The repository explicitly states it is a native Clojure implementation of the Model Context Protocol (MCP). It implements the `stdio` transport and aims for compliance with the MCP specification.","categories":["Protocol Implementations","Function Calling","AI Model Integration"],"analysis":{"Architecture and Design Patterns":"Modex is structured as both a client and server for the Model Context Protocol (MCP), written in Clojure. It uses an uberjar for deployment, simplifying the process. The design emphasizes direct communication via `stdio`, avoiding intermediate proxies. The system is designed to expose tools to AI models.","Implementation Details and Key Features":"The core implementation centers around the `stdio` transport, facilitating communication between the MCP client and server. The server exposes a tool named 'foo' to interact with the AI model. Messages are encoded using JSON-RPC 2.0. The project aims for compliance with the 2024-11-05 MCP Specification.","Integration Approaches and Protocols":"Modex integrates with AI models via the Model Context Protocol. It communicates using `stdio`, allowing direct interaction between the MCP client (e.g., Claude Desktop) and server. The protocol uses JSON-RPC 2.0 for message encoding, supporting requests, responses, and notifications.","Technical Stack and Dependencies":"The project is built using Clojure and requires Java. It uses `build.sh` script to create an uberjar for deployment. The uberjar contains all dependencies, making it easy to run. Claude Desktop is used as a test MCP client.","Best Practices and Coding Standards":"The project includes tests, indicating a focus on code quality. The documentation provides clear instructions for building and configuring the server. The license is explicitly defined. The code is structured to be mostly compliant with the MCP Spec.","Performance Considerations":"The implementation prioritizes direct communication via `stdio` to minimize latency. The choice of Clojure allows leveraging the JVM's performance. The use of an uberjar streamlines deployment and potentially improves startup time. Further performance considerations could involve optimizing JSON-RPC message handling."}}', '2025-03-10 21:28:52+00', 'modex-clojure-mcp', 'true', 'true'), ('944014927', 'browser-use-mcp-client', 'Linzo99/browser-use-mcp-client', 'https://github.com/Linzo99/browser-use-mcp-client', 'A MCP client for browser-use', '2025-03-06 16:36:11+00', '2025-03-09 23:47:27+00', 'TypeScript', '8', '# Browser-use MCP Client

A modern React application that provides a user-friendly interface for interacting with Model Context Protocol (MCP) servers through Server-Sent Events (SSE).

## 🎥 Demo
https://github.com/user-attachments/assets/52ab11ad-741f-4506-99ad-9f1972a3aad1

## 🚀 Features

- **Real-time Communication**: Direct SSE connection to MCP servers
- **Interactive UI**: Clean and responsive interface built with React and Tailwind CSS
- **Theme Support**: Light and dark mode with system preference detection
- **Screenshot Preview**: Live browser screenshots from MCP server responses
- **Message History**: Persistent chat history with clear message threading
- **Request Management**: Cancel in-progress requests and clear chat history
- **Connection Management**: Easy server connection configuration

## 📋 Prerequisites

- Node.js (v18 or later)
- pnpm (recommended package manager)
- A running MCP server for connection
- Python 3.8+ (for running the example server)
-

## 🚀 Getting Started

1. **Clone the Repository**

   ```bash
   git clone <repository-url>
   cd browser-use-mcp-client
   ```

2. **Install Dependencies**

   ```bash
   pnpm install
   ```

3. **Start the Development Server**

   ```bash
   pnpm dev
   ```

4. **Start the Proxy Server**

   ```bash
   ./proxy/index.js
   ```

The application will be available at `http://localhost:5173`

## 💻 Usage

## 🤖 Example MCP Server

Here's an example of a Python-based MCP server that uses browser automation:

```python
#!/usr/bin/env python3
import asyncio
from dotenv import load_dotenv
from typing import Awaitable, Callable
from mcp.server.fastmcp import FastMCP, Context
from browser_use import Agent, Browser, BrowserConfig
from langchain_google_genai import ChatGoogleGenerativeAI

# Load environment variables from .env file
load_dotenv()

# Initialize FastMCP server
mcp = FastMCP("browser-use")

browser = Browser(
    config=BrowserConfig(
        chrome_instance_path="/Applications/Google Chrome.app/Contents/MacOS/Google Chrome --remote-debugging-port=9222",
        headless=True
    )
)

llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")
agent = None


@mcp.tool()
async def perform_search(task: str, context: Context):
    """Perform the actual search in the background."""
    async def step_handler(state, *args):
        if len(args) != 2:
            return
        await context.session.send_log_message(
            level="info",
            data={"screenshot": state.screenshot, "result": args[0]}
        )

    asyncio.create_task(
        run_browser_agent(task=task, on_step=step_handler)
    )
    return "Processing Request"


@mcp.tool()
async def stop_search(*, context: Context):
    """Stop a running browser agent search by task ID."""
    if agent is not None:
        await agent.stop()
    return "Running Agent stopped"


async def run_browser_agent(task: str, on_step: Callable[[], Awaitable[None]]):
    """Run the browser-use agent with the specified task."""
    global agent
    try:
        agent = Agent(
            task=task,
            browser=browser,
            llm=llm,
            register_new_step_callback=on_step,
            register_done_callback=on_step,
        )

        await agent.run()
    except asyncio.CancelledError:
        return "Task was cancelled"

    except Exception as e:
        return f"Error during execution: {str(e)}"
    finally:
        await browser.close()

if __name__ == "__main__":
    mcp.run(transport="sse")
```

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
', '"{\"AI Model Integration\",\"Protocol Implementations\",\"Browser & Web Automation\"]}', '{"is_mcp":"YES","justification":"The repository description and documentation explicitly mention Model Context Protocol (MCP) and interacting with MCP servers via Server-Sent Events (SSE). The example MCP server provided further confirms this.","categories":["AI Model Integration","Protocol Implementations","Developer Tooling"],"analysis":{"Architecture and Design Patterns":"The client application is built with React and Tailwind CSS, suggesting a component-based architecture for the user interface. The application utilizes Server-Sent Events (SSE) for real-time communication with the MCP server, which likely employs an event-driven design. The use of a proxy server implies a separation of concerns, possibly for handling CORS or other cross-domain issues.","Implementation Details and Key Features":"The client facilitates real-time communication with MCP servers. Key features include screenshot previews from server responses, persistent message history, and request management (canceling in-progress requests). Theme support (light/dark mode) enhances user experience. The example server uses Python and libraries like `browser_use`, `langchain-google-genai`, and `fastmcp` to implement the MCP server logic.","Integration Approaches and Protocols":"The application integrates with MCP servers using Server-Sent Events (SSE). The provided example server demonstrates integration with browser automation tools and Language Model Models (LLMs). The example makes uses of BrowserUse and Langchain. The server exposes tools via the MCP.","Technical Stack and Dependencies":"The client-side uses React, Tailwind CSS, Node.js, and pnpm. The server-side example uses Python 3.8+ and depends on libraries such as `fastmcp`, `browser_use`, `langchain-google-genai`, and `python-dotenv`. The example's usage of Chrome requires a specific installation path and a remote debugging port.","Best Practices and Coding Standards":"The repository follows standard practices for React-based web development, utilizing a modern component framework. The inclusion of a LICENSE file (MIT License) and a CONTRIBUTING section suggests attention to open-source best practices. The usage of a package manager (pnpm) and environment variables via `dotenv` reflects adherence to modern development workflows.","Performance Considerations":"Real-time communication through SSE can introduce performance considerations related to connection management and data transfer rates. Browser automation, as exemplified in the server, can be resource-intensive, impacting responsiveness. The use of asynchronous operations and message queueing (implicit in SSE) may be employed to mitigate performance bottlenecks."}}', '2025-03-10 21:54:07+00', 'browser-use-mcp-944014927', 'true', 'true'), ('944041703', 'mcp-durable-object-client', 'Dhravya/mcp-durable-object-client', 'https://github.com/Dhravya/mcp-durable-object-client', 'testing mcps', '2025-03-06 17:28:05+00', '2025-03-10 05:01:05+00', 'TypeScript', '49', '# 🤖 MCP Client as a durable object

This example shows a working pattern using durable objects as an MCP client.

To start, install depdencies in `/` and `/server`

```
npm i
```
To start the server, run `npm run start` in `server/`

To start the client, run `npm run start` in `/`


Ask `Can you add 5 and 6`?

The client will make a call to the server, get the response and show it to the client.

## License

MIT
', '"{\"Protocol Implementations\",\"Agent Frameworks\",\"Function Calling\"]}', '{"is_mcp":"YES","justification":"The repository explicitly mentions 'MCP Client' and demonstrates its implementation using durable objects, showcasing a communication protocol pattern between a client and server.","categories":["Protocol Implementations","API Frameworks","AI Model Integration"],"analysis":{"Architecture and Design Patterns":"The repository implements a client-server architecture using durable objects. The client initiates requests, and the server processes these requests, returning a response. The use of durable objects suggests a focus on persistent state and reliable message handling. The pattern facilitates decoupled communication between components.","Implementation Details and Key Features":"The core functionality involves sending a request from the client to the server and receiving a response. The example uses a simple addition task to illustrate the communication flow. Key features include dependency management using npm and separate startup scripts for the client and server components.","Integration Approaches and Protocols":"The integration relies on a custom protocol implemented over HTTP or a similar network transport. Durable objects facilitate reliable communication and state management. The provided example demonstrates a basic request-response interaction model suitable for integrating AI models with external tools or services.","Technical Stack and Dependencies":"The repository utilizes JavaScript and Node.js. Dependencies include npm for package management. The use of durable objects suggests a Cloudflare Workers environment or a similar serverless platform. The stack enables rapid prototyping and deployment of microservices.","Best Practices and Coding Standards":"The repository includes basic instructions for setup and execution, adhering to common npm practices. The structure of client and server directories promotes modularity. The MIT license encourages open-source collaboration and usage.","Performance Considerations":"The use of durable objects can provide performance benefits through persistent connections and efficient state management. The serverless architecture allows for scaling based on demand. However, network latency and object serialization overhead should be considered for performance optimization."}}', '2025-03-10 21:28:23+00', 'mcp-durable-object', 'true', 'true'), ('944216248', 'mcp-client-server-host-demo', 'danwritecode/mcp-client-server-host-demo', 'https://github.com/danwritecode/mcp-client-server-host-demo', 'A quick pokemon demo to showcase MCP server, client, and host', '2025-03-07 01:17:01+00', '2025-03-09 06:36:01+00', 'TypeScript', '33', '# Pokemon MCP Demo

A demo project showcasing the Model Context Protocol (MCP) integration with Pokemon data. This project includes:

- An MCP server that provides Pokemon data and attack capabilities
- An MCP client that interacts with the server
- An HTTP server that allows LLMs to use Pokemon tools via OpenRouter

## Installation

```bash
bun install
```

## Running the Project

### MCP Server and Client Demo
Run the client which automatically launches the MCP server:

```bash
bun mcp_client.ts
```

### HTTP Server with LLM Integration
Set your OpenRouter API key and run the HTTP server:

```bash
export OPENROUTER_API_KEY=your_api_key_here
bun http_server.ts
```

Then access the server at http://localhost:3005:
- `/tools` - List available tools
- `/attack` - Execute a random Pokemon attack using LLM

This project uses [Bun](https://bun.sh) as its JavaScript runtime.', '"{\"Protocol Implementations\",\"Function Calling\",\"AI Model Integration\"]}', '{"is_mcp":"YES","justification":"The repository description and documentation explicitly mention Model Context Protocol (MCP) integration and demonstrate server, client, and host implementations with Pokemon data and attack capabilities.","categories":["Protocol Implementations","AI Model Integration","Function Calling"],"analysis":{"Architecture and Design Patterns":"The repository adopts a client-server architecture, where an MCP server provides Pokemon data and attack capabilities, and an MCP client interacts with this server. An HTTP server bridges the MCP functionalities to LLMs through OpenRouter, enabling tool use. The architecture uses a demo approach to illustrate key MCP concepts and usage.","Implementation Details and Key Features":"The implementation features an MCP server offering Pokemon data and attack functions, a client interacting with this server, and an HTTP server allowing LLMs to access Pokemon tools via OpenRouter. Key features include tool listing and attack execution, showcasing MCP's function calling capabilities. The use of Bun as the runtime simplifies project setup and execution.","Integration Approaches and Protocols":"The repository integrates MCP with an HTTP server, enabling LLMs to leverage Pokemon tools using OpenRouter. The `/tools` endpoint lists available functions, while `/attack` executes a random attack using an LLM. This demonstrates MCP's ability to facilitate tool use and function calling in language models. The integration is designed to be easily accessible and testable.","Technical Stack and Dependencies":"The project primarily uses Bun as its JavaScript runtime. It depends on the OpenRouter API for integrating LLMs with the MCP functionalities. The code is written in TypeScript (as indicated by the .ts file extensions). The stack is lightweight, aiming for ease of use and rapid prototyping of MCP-related concepts.","Best Practices and Coding Standards":"The documentation includes clear instructions for installation and running the project, including setting up the OpenRouter API key. The repository provides specific examples for using the HTTP server endpoints, promoting ease of use and understanding. Use of TypeScript suggests an attention to type safety and code maintainability within the project.","Performance Considerations":"The demo nature of the repository suggests that performance optimization might not be the primary focus. However, the choice of Bun runtime could contribute to reasonable execution speed. The impact of OpenRouter API usage on latency should be evaluated for real-world implementations. The simple nature of the demo should reduce the performance impact overall."}}', '2025-03-10 21:28:52+00', 'mcp-pokemon-demo', 'true', 'true'), ('944691576', 'mcp-sdk', 'php-llm/mcp-sdk', 'https://github.com/php-llm/mcp-sdk', 'Model Context Protocol SDK for Client and Server applications in PHP', '2025-03-07 19:50:35+00', '2025-03-10 01:44:27+00', 'PHP', '3', '# Model Context Protocol PHP SDK [WIP]

Model Context Protocol SDK for Client and Server applications in PHP.

See [Demo App](https://github.com/php-llm/mcp-demo) for a working example.

## Installation

```bash
composer require php-llm/mcp-sdk
```

## Usage with Symfony

Server integration points for are tailored to Symfony Console and HttpFoundation (Laravel compatible).

### Console Command for STDIO Server

```php
namespace App\Command;

use PhpLlm\McpSdk\Server;
use PhpLlm\McpSdk\Server\Transport\Stdio\SymfonyConsoleTransport;
use Symfony\Component\Console\Attribute\AsCommand;
use Symfony\Component\Console\Command\Command;
use Symfony\Component\Console\Input\InputInterface;
use Symfony\Component\Console\Output\OutputInterface;

#[AsCommand('mcp', 'Starts an MCP server')]
final class McpCommand extends Command
{
    public function __construct(
        private readonly Server $server,
    ) {
        parent::__construct();
    }

    protected function execute(InputInterface $input, OutputInterface $output): int
    {
        $this->server->connect(
            new SymfonyConsoleTransport($input, $output)
        );

        return Command::SUCCESS;
    }
}
```

### Controller for Server-Sent Events Server

```php
namespace App\Controller;

use PhpLlm\McpSdk\Server;
use PhpLlm\McpSdk\Server\Transport\Sse\Store\CachePoolStore;
use PhpLlm\McpSdk\Server\Transport\Sse\StreamTransport;
use Symfony\Component\HttpFoundation\Request;
use Symfony\Component\HttpFoundation\Response;
use Symfony\Component\HttpFoundation\StreamedResponse;
use Symfony\Component\HttpKernel\Attribute\AsController;
use Symfony\Component\Routing\Attribute\Route;
use Symfony\Component\Routing\Generator\UrlGeneratorInterface;
use Symfony\Component\Uid\Uuid;

#[AsController]
#[Route('/mcp', name: 'mcp_')]
final readonly class McpController
{
    public function __construct(
        private Server $server,
        private CachePoolStore $store,
        private UrlGeneratorInterface $urlGenerator,
    ) {
    }

    #[Route('/sse', name: 'sse', methods: ['GET'])]
    public function sse(): StreamedResponse
    {
        $id = Uuid::v4();
        $endpoint = $this->urlGenerator->generate('mcp_messages', ['id' => $id], UrlGeneratorInterface::ABSOLUTE_URL);
        $transport = new StreamTransport($endpoint, $this->store, $id);

        return new StreamedResponse(fn() => $this->server->connect($transport), headers: [
            'Content-Type' => 'text/event-stream',
            'Cache-Control' => 'no-cache',
            'X-Accel-Buffering' => 'no',
        ]);
    }

    #[Route('/messages/{id}', name: 'messages', methods: ['POST'])]
    public function messages(Request $request, Uuid $id): Response
    {
        $this->store->push($id, $request->getContent());

        return new Response();
    }
}
```

### Exposing Tools

Under the hood the SDK uses [LLM Chain](https://github.com/php-llm/llm-chain)'s `ToolBox` to register, analyze and
execute tools. In combination with its [Symfony Bundle](https://github.com/php-llm/llm-chain-bundle) you can expose
tools with `#[AsTool]` attribute.

```php
use PhpLlm\LlmChain\ToolBox\Attribute\AsTool;

#[AsTool('company_name', 'Provides the name of your company')]
final class CompanyName
{
    public function __invoke(): string
    {
        return 'ACME Corp.'
    }
}
```
See [LLM Chain Documentation](https://github.com/php-llm/llm-chain?tab=readme-ov-file#tools) for more information.
', '"{\"Protocol Implementations\",\"API Frameworks\",\"AI Model Integration\"]}', '{"is_mcp":"YES","justification":"The repository is named \"mcp-sdk\" and the description states it's a Model Context Protocol SDK. The documentation shows server integrations for Symfony, handling communication between models and external contexts via console and HTTP.","categories":["Protocol Implementations","API Frameworks","AI Model Integration"],"analysis":{"Architecture and Design Patterns":"The SDK provides a server implementation for the Model Context Protocol (MCP), supporting different transport mechanisms like STDIO and Server-Sent Events (SSE). It utilizes a transport abstraction to handle communication. The design appears to be modular, allowing easy integration with Symfony and potentially other PHP frameworks.","Implementation Details and Key Features":"The SDK provides Symfony Console command and controller examples for implementing MCP servers. It leverages the `php-llm/llm-chain` library for tool management, using the `ToolBox` and `AsTool` attribute for tool registration and execution. The server connects using different transports such as SymfonyConsoleTransport and StreamTransport.","Integration Approaches and Protocols":"The SDK integrates with Symfony framework via Console commands and HTTP controllers. It supports STDIO for console-based interactions and Server-Sent Events (SSE) for web-based, real-time communication. It relies on HTTP for message exchange and leverages Symfony's routing and request handling components.","Technical Stack and Dependencies":"The project is written in PHP and uses Composer for dependency management. Key dependencies include Symfony components (Console, HttpFoundation, Routing, Cache), `php-llm/llm-chain` for tool management, and potentially others managed through Composer. It supports Uuids for unique identifier generation.","Best Practices and Coding Standards":"The provided code snippets demonstrate the use of modern PHP features like readonly properties and attributes for defining console commands and tools. The code follows PSR coding standards, utilizes namespaces for organization, and employs dependency injection for managing dependencies.","Performance Considerations":"The SSE server implementation utilizes `StreamedResponse` in Symfony for efficient handling of real-time data streams. The SDK leverages a cache pool store for managing messages in the SSE transport. Performance considerations would depend on the specific transport used and the volume of data being transmitted."}}', '2025-03-10 21:54:07+00', 'mcp-php-sdk', 'true', 'true'), ('944715410', 'agent-twitter-client-mcp', 'ryanmac/agent-twitter-client-mcp', 'https://github.com/ryanmac/agent-twitter-client-mcp', 'A Model Context Protocol (MCP) server that integrates with X using the @elizaOS `agent-twitter-client` package, allowing AI models to interact with Twitter without direct API access.', '2025-03-07 20:54:02+00', '2025-03-10 17:46:52+00', 'TypeScript', '1', '# agent-twitter-client-mcp

[![npm version](https://img.shields.io/npm/v/agent-twitter-client-mcp.svg)](https://www.npmjs.com/package/agent-twitter-client-mcp)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Node.js Version](https://img.shields.io/node/v/agent-twitter-client-mcp.svg)](https://nodejs.org)

A Model Context Protocol (MCP) server that integrates with Twitter using the `agent-twitter-client` package, allowing AI models to interact with Twitter without direct API access.

## Features

- **Authentication Options**:

  - Cookie-based authentication (recommended)
  - Username/password authentication
  - Twitter API v2 credentials

- **Tweet Operations**:

  - Fetch tweets from users
  - Get specific tweets by ID
  - Search tweets
  - Send tweets with text and media
  - Create polls
  - Like, retweet, and quote tweets

- **User Operations**:

  - Get user profiles
  - Follow users
  - Get followers and following lists

- **Grok Integration**:
  - Chat with Grok via Twitter's interface
  - Continue conversations with conversation IDs
  - Get web search results and citations
  - Access Twitter's real-time data through Grok
  - **Note**: Grok functionality requires [agent-twitter-client v0.0.19](https://github.com/elizaOS/agent-twitter-client/releases/tag/0.0.19) or higher

## Documentation

- [Developer Guide](docs/DEVELOPER_GUIDE.md) - Comprehensive guide for developers
- [Testing Guide](docs/TESTING.md) - Instructions for testing the MCP
- [Agent Guide](docs/AGENT_GUIDE.md) - Guide for AI agents on how to use the Twitter MCP
- [Contributing Guide](CONTRIBUTING.md) - Guidelines for contributing to this project
- [Changelog](CHANGELOG.md) - History of changes to this project
- [Demo README](demo/README.md) - Guide for running the demo scripts
- [Grok Examples](demo/GROK_EXAMPLES.md) - Documentation for the Grok AI integration examples

## Quick Start

### Installation

```bash
# Install globally
npm install -g agent-twitter-client-mcp

# Or install locally
npm install agent-twitter-client-mcp
```

### Basic Usage

1. Create a `.env` file with your Twitter credentials (see [Authentication Methods](#authentication-methods))
2. Run the MCP server:

```bash
# If installed globally
agent-twitter-client-mcp

# If installed locally
npx agent-twitter-client-mcp
```

### Demo Scripts

The package includes a `demo` directory with example scripts that demonstrate various features:

```bash
# Clone the repository to access the demo scripts
git clone https://github.com/ryanmac/agent-twitter-client-mcp.git
cd agent-twitter-client-mcp/demo

# Run the interactive demo menu
./run-demo.sh

# Run a specific demo script
./run-demo.sh --script tweet-search.js

# Run Grok AI examples (requires agent-twitter-client v0.0.19)
./run-demo.sh --script simple-grok.js --use-local-agent-twitter-client
./run-demo.sh --script grok-chat.js --use-local-agent-twitter-client
```

See the [Demo README](demo/README.md) for more details.

### Port Configuration

By default, the MCP server runs on port 3000. If you need to change this (for example, if you already have an application running on port 3000), you have several options:

#### Option 1: Using Environment Variables

Set the `PORT` environment variable:

```bash
PORT=3001 npx agent-twitter-client-mcp
```

#### Option 2: Using Docker Compose

If using Docker Compose, you can configure both the host and container ports in your `.env` file:

```
# .env file
MCP_HOST_PORT=3001    # The port on your host machine
MCP_CONTAINER_PORT=3000  # The port inside the container
```

Then run:

```bash
docker-compose up -d
```

This will map port 3001 on your host to port 3000 in the container, allowing you to access the MCP at http://localhost:3001 while your other application continues to use port 3000.

### Setup with Claude Desktop

1. Configure Claude Desktop to use this MCP by adding to your config file:

**Windows**: `%APPDATA%\Claude\claude_desktop_config.json`
**macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`

```json
{
  "mcpServers": {
    "agent-twitter-client-mcp": {
      "command": "npx",
      "args": ["-y", "agent-twitter-client-mcp"],
      "env": {
        "AUTH_METHOD": "cookies",
        "TWITTER_COOKIES": "[\"auth_token=YOUR_AUTH_TOKEN; Domain=.twitter.com\", \"ct0=YOUR_CT0_VALUE; Domain=.twitter.com\", \"twid=u%3DYOUR_USER_ID; Domain=.twitter.com\"]"
      }
    }
  }
}
```

2. Restart Claude Desktop

### Authentication Methods

#### Cookie Authentication (Recommended)

```json
{
  "AUTH_METHOD": "cookies",
  "TWITTER_COOKIES": "[\"auth_token=YOUR_AUTH_TOKEN; Domain=.twitter.com\", \"ct0=YOUR_CT0_VALUE; Domain=.twitter.com\", \"twid=u%3DYOUR_USER_ID; Domain=.twitter.com\"]"
}
```

To obtain cookies:

1. Log in to Twitter in your browser
2. Open Developer Tools (F12)
3. Go to the Application tab > Cookies
4. Copy the values of `auth_token`, `ct0`, and `twid` cookies
5. Make sure to include the `Domain=.twitter.com` part for each cookie

#### Username/Password Authentication

```json
{
  "AUTH_METHOD": "credentials",
  "TWITTER_USERNAME": "your_username",
  "TWITTER_PASSWORD": "your_password",
  "TWITTER_EMAIL": "your_email@example.com", // Optional
  "TWITTER_2FA_SECRET": "your_2fa_secret" // Optional, required if 2FA is enabled
}
```

#### Twitter API Authentication

```json
{
  "AUTH_METHOD": "api",
  "TWITTER_API_KEY": "your_api_key",
  "TWITTER_API_SECRET_KEY": "your_api_secret_key",
  "TWITTER_ACCESS_TOKEN": "your_access_token",
  "TWITTER_ACCESS_TOKEN_SECRET": "your_access_token_secret"
}
```

## Available Tools

- `get_user_tweets`: Fetch tweets from a specific user
- `get_tweet_by_id`: Fetch a specific tweet by ID
- `search_tweets`: Search for tweets
- `send_tweet`: Post a new tweet
- `send_tweet_with_poll`: Post a tweet with a poll
- `like_tweet`: Like a tweet
- `retweet`: Retweet a tweet
- `quote_tweet`: Quote a tweet
- `get_user_profile`: Get a user's profile
- `follow_user`: Follow a user
- `get_followers`: Get a user's followers
- `get_following`: Get users a user is following
- `grok_chat`: Chat with Grok via Twitter
- `health_check`: Check the health of the Twitter MCP server

## Testing Interface

The MCP includes an interactive command-line interface for testing:

```bash
npx agent-twitter-client-mcp-test
# or if installed locally
npm run test:interface
```

This launches a REPL where you can test various MCP functions:

```
agent-twitter-client-mcp> help

Available commands:
  health                     Run a health check
  profile <username>         Get a user profile
  tweets <username> [count]  Get tweets from a user
  tweet <id>                 Get a specific tweet by ID
  search <query> [count]     Search for tweets
  post <text>                Post a new tweet
  like <id>                  Like a tweet
  retweet <id>               Retweet a tweet
  quote <id> <text>          Quote a tweet
  follow <username>          Follow a user
  followers <userId> [count] Get a user's followers
  following <userId> [count] Get users a user is following
  grok <message>             Chat with Grok
  help                       Show available commands
  exit                       Exit the test interface
```

### Example Test Commands

```
# Run a health check
agent-twitter-client-mcp> health

# Search for tweets
agent-twitter-client-mcp> search mcp 2

# Get a user's profile
agent-twitter-client-mcp> profile elonmusk

# Get tweets from a user
agent-twitter-client-mcp> tweets openai 5

# Chat with Grok
agent-twitter-client-mcp> grok Explain quantum computing in simple terms
```

## Example Usage

Ask Claude to:

- "Search Twitter for tweets about AI"
- "Post a tweet saying 'Hello from Claude!'"
- "Get the latest tweets from @OpenAI"
- "Chat with Grok about quantum computing"

## Advanced Usage

### Working with Media

To post a tweet with an image:

```
I want to post a tweet with an image. The tweet should say "Beautiful sunset today!" and include this image.
```

To post a tweet with a video:

```
I want to post a tweet with a video. The tweet should say "Check out this amazing video!" and include the video file.
```

### Creating Polls

To create a poll:

```
Create a Twitter poll asking "What's your favorite programming language?" with options: Python, JavaScript, Rust, and Go. The poll should run for 24 hours.
```

### Interacting with Grok

To have a conversation with Grok:

```
Use Grok to explain quantum computing to me. Ask it to include some real-world applications.
```

To continue a conversation with Grok:

```
Continue the Grok conversation and ask it to elaborate on quantum entanglement.
```

### Grok's Unique Capabilities

Grok on Twitter has access to real-time Twitter data that even the standalone Grok API doesn't have. This means you can ask Grok about:

- Current trending topics on Twitter
- Analysis of recent tweets on specific subjects
- Information about Twitter users and their content
- Real-time events being discussed on the platform

Example queries:

- "What are the trending topics on Twitter right now?"
- "Analyze the sentiment around AI on Twitter"
- "What are people saying about the latest Apple event?"
- "Show me information about popular memecoins being discussed today"

### Grok Authentication Requirements

Grok functionality requires proper authentication. The MCP supports two methods:

1. **Cookie Authentication** (Recommended):

   - Cookies must be in JSON array format
   - Example: `TWITTER_COOKIES=["auth_token=YOUR_AUTH_TOKEN; Domain=.twitter.com", "ct0=YOUR_CT0_VALUE; Domain=.twitter.com", "twid=u%3DYOUR_USER_ID; Domain=.twitter.com"]`
   - Essential cookies are `auth_token`, `ct0`, and `twid`

2. **Username/Password Authentication**:
   - Set `TWITTER_USERNAME` and `TWITTER_PASSWORD` in your environment
   - May encounter Cloudflare protection in some cases

### Grok Rate Limits

Grok has rate limits that may affect usage:

- Non-premium accounts: 25 messages per 2 hours
- Premium accounts: Higher limits

The MCP will return rate limit information in the response when limits are reached.

For more details on using Grok, see the [Grok Examples](demo/GROK_EXAMPLES.md) documentation.

## Troubleshooting

### Authentication Issues

#### Cookie Authentication Problems

If you're experiencing issues with cookie authentication:

1. **Cookie Expiration**: Twitter cookies typically expire after a certain period. Try refreshing your cookies by logging out and back into Twitter.
2. **Cookie Format**: Ensure your cookies are properly formatted as a JSON array of strings with the correct domain.
3. **Required Cookies**: Make sure you've included the essential cookies: `auth_token`, `ct0`, and `twid`.

Example of properly formatted cookies:

```json
"TWITTER_COOKIES": "[\"auth_token=1234567890abcdef; Domain=.twitter.com\", \"ct0=abcdef1234567890; Domain=.twitter.com\", \"twid=u%3D1234567890; Domain=.twitter.com\"]"
```

#### Credential Authentication Problems

If you're having trouble with username/password authentication:

1. **Two-Factor Authentication**: If your account has 2FA enabled, you'll need to provide the `TWITTER_2FA_SECRET`.
2. **Account Lockouts**: Too many failed login attempts may lock your account. Check your email for account verification requests.
3. **Captcha Challenges**: Twitter may present captcha challenges that the client can't handle automatically.

#### API Authentication Problems

For API authentication issues:

1. **API Key Permissions**: Ensure your API keys have the necessary permissions for the actions you're trying to perform.
2. **Rate Limiting**: Twitter API has rate limits that may cause failures if exceeded.
3. **API Changes**: Twitter occasionally changes its API, which may cause compatibility issues.

### Operation Errors

#### Tweet Posting Failures

If you can't post tweets:

1. **Content Restrictions**: Twitter may block tweets that violate its content policies.
2. **Media Format Issues**: Ensure media is properly formatted and encoded.
3. **Rate Limiting**: Twitter limits how frequently you can post.

#### Search Problems

If search isn't working:

1. **Query Syntax**: Ensure your search query follows Twitter's search syntax.
2. **Search Limitations**: Some search modes may have restrictions or require specific permissions.

#### Grok Issues

If Grok functionality isn't working:

1. **Version Requirement**:

   - Grok requires [agent-twitter-client v0.0.19](https://github.com/elizaOS/agent-twitter-client/releases/tag/0.0.19) or higher
   - The current package uses v0.0.18 for basic functionality
   - For the demo scripts, use the `--use-local-agent-twitter-client` flag to temporarily install v0.0.19

2. **Authentication Issues**:

   - Cookie Format: Ensure cookies are in the correct JSON array format
   - Cookie Validity: Twitter cookies expire after a certain period
   - Cloudflare Protection: Username/password authentication may be blocked by Cloudflare
   - Premium Requirement: Grok access requires a Twitter Premium subscription

3. **Rate Limits**:

   - Non-premium accounts: 25 messages per 2 hours
   - Error Message: "Rate Limited: You've reached the limit..."
   - Solution: Wait until the rate limit resets or upgrade to a premium account

4. **Environment File Location**:
   - For the demo scripts, make sure your credentials are in `demo/.env`, not in the root `.env` file
   - Use the `--debug-env` flag to check which environment variables are being loaded

For detailed troubleshooting of Grok issues, see the [Grok Examples](demo/GROK_EXAMPLES.md) documentation.

### Server Issues

#### Health Check

Use the `health_check` tool to diagnose server issues:

```
Run a health check on the agent-twitter-client-mcp server to diagnose any issues.
```

The health check will report on:

- Authentication status
- API connectivity
- Memory usage

#### Logging

The server logs to both console and files:

- `error.log`: Contains error-level messages
- `combined.log`: Contains all log messages

Check these logs for detailed error information.

## Development

### Prerequisites

- Node.js 18+
- npm

### Setup

1. Clone the repository

```bash
git clone https://github.com/ryanmac/agent-twitter-client-mcp.git
cd agent-twitter-client-mcp
```

2. Install dependencies

```bash
npm install
```

3. Create a `.env` file with configuration:

```
AUTH_METHOD=cookies
TWITTER_COOKIES=["cookie1=value1", "cookie2=value2"]
```

4. Build the project

```bash
npm run build
```

5. Start the server

```bash
npm start
```

### Environment Variables

In addition to the authentication variables, you can set:

- `LOG_LEVEL`: Set logging level (error, warn, info, debug)
- `NODE_ENV`: Set environment (development, production)

## Docker

You can also run the server using Docker:

### Using Docker Directly

```bash
# Build the Docker image
docker build -t agent-twitter-client-mcp .

# Run the container with environment variables
docker run -p 3000:3000 \
  -e AUTH_METHOD=cookies \
  -e TWITTER_COOKIES='["auth_token=YOUR_AUTH_TOKEN; Domain=.twitter.com", "ct0=YOUR_CT0_VALUE; Domain=.twitter.com"]' \
  agent-twitter-client-mcp
```

### Using Docker Compose

1. Create a `.env` file with your Twitter credentials
2. Run with docker-compose:

```bash
# Start the service
docker-compose up -d

# View logs
docker-compose logs -f

# Stop the service
docker-compose down
```

### Environment Variables in Docker

You can pass environment variables to the Docker container in several ways:

1. **In the docker-compose.yml file** (already configured)
2. **Through a .env file** (recommended for docker-compose)
3. **Directly in the docker run command** (as shown above)

### Persisting Logs

The docker-compose configuration includes a volume mount for logs:

```yaml
volumes:
  - ./logs:/app/logs
```

This will store logs in a `logs` directory in your project folder.

## Security Considerations

- **Credential Storage**: Store credentials securely, preferably using environment variables or a secure vault.
- **Rate Limiting**: Implement rate limiting to prevent abuse of the Twitter API.
- **Content Validation**: Validate all content before posting to prevent malicious use.

## License

MIT
', '"{\"Agent Frameworks\",\"Function Calling\",\"API Frameworks\"]}', '{"is_mcp":"YES","justification":"The repository implements a Model Context Protocol (MCP) server to allow AI models to interact with Twitter via an intermediary, abstracting away direct API access and providing tools for agents.","categories":["Agent Frameworks","API Frameworks","Function Calling"],"analysis":{"Architecture and Design Patterns":"The repository implements an MCP server acting as an intermediary between AI models and the Twitter API. It utilizes a modular design with different authentication methods (cookies, username/password, API keys). The server exposes a set of tools that AI agents can utilize through a well-defined interface, effectively abstracting away the complexities of the Twitter API.","Implementation Details and Key Features":"Key features include various authentication methods, tweet operations (fetching, searching, sending, liking), user operations (profiles, follow/unfollow, lists), and Grok integration. It uses Node.js, and is packaged as an npm module, making it easy to install and use. The inclusion of demo scripts further illustrates usage and functionalities.","Integration Approaches and Protocols":"The integration with AI models occurs through the Model Context Protocol. The server exposes a set of functions/tools that the AI models can call. The repository also integrates with Claude Desktop through configuration file settings. Integration with Twitter is achieved via the `agent-twitter-client` package, providing an abstraction layer for Twitter API interactions.","Technical Stack and Dependencies":"The core technical stack includes Node.js, npm, and potentially Docker for deployment. The repository depends on the `@elizaOS/agent-twitter-client` package for interacting with the Twitter API. Other dependencies are likely present but not explicitly detailed. The project utilizes environment variables for configuration and authentication.","Best Practices and Coding Standards":"The repository demonstrates several best practices, including the use of comprehensive documentation (developer, testing, agent guides), a changelog, and demo scripts. It also includes a contributing guide to encourage external contributions. The use of environment variables for configuration and authentication is another indicator of good practices.","Performance Considerations":"The repository highlights rate limits for Grok integration, indicating an awareness of potential performance bottlenecks. Health check functionality and logging mechanisms are in place to monitor server health and diagnose issues. Authentication methods and efficient Twitter API interaction should be considered for performance optimization."}}', '2025-03-10 21:26:36+00', 'agent-twitter-mcp', 'true', 'true'), ('945099804', 'mcp-client-dumb', 'anaisbetts/mcp-client-dumb', 'https://github.com/anaisbetts/mcp-client-dumb', 'The dumbest MCP client', '2025-03-08 16:55:46+00', '2025-03-09 02:39:25+00', 'JavaScript', '2', '# The Dumbest MCP Client

The world's simplest example of a client for interacting with Claude AI using the Model Context Protocol (MCP) to enable tool usage with YouTube context.

## Overview

This project provides a command-line interface for sending prompts to Anthropic's Claude AI model while giving it access to YouTube-related tools through the Model Context Protocol. The client connects Claude to an MCP YouTube server, allowing the AI to retrieve and process information from YouTube videos when responding to user prompts.

## Prerequisites

- Node.js (v18+)
- Bun runtime
- Anthropic API key

## Installation

1. Clone the repository:
   ```
   git clone https://github.com/anaisbetts/mcp-client.git
   cd mcp-client
   ```

2. Install dependencies:
   ```
   bun install
   ```

3. Set up your Anthropic API key:
   ```
   export ANTHROPIC_API_KEY=your_api_key_here
   ```
   
   On Windows, use:
   ```
   $env:ANTHROPIC_API_KEY=your_api_key_here
   ```

## Usage

Run the client with a prompt:

```
bun start "Your prompt here"
```

Example:

```
bun start "Find me information about the latest SpaceX launch from this YouTube video: https://www.youtube.com/watch?v=example"
```

## Development

- Run in development mode with hot reloading:
  ```
  bun dev
  ```

- Build the project:
  ```
  bun build
  ```

- Run TypeScript type checking:
  ```
  bun typecheck
  ```

- Run tests:
  ```
  bun test
  ```

## How It Works

1. The client initializes an Anthropic client with your API key
2. It starts an MCP YouTube server process
3. The client connects to the MCP server and retrieves available tools
4. These tools are converted to Anthropic's tool format
5. Your prompt is sent to Claude along with the available tools
6. If Claude uses a tool, the request is forwarded to the MCP server
7. The tool response is sent back to Claude for further processing
8. The final response is displayed in the console

## License

ISC

## Dependencies

- @anthropic-ai/sdk: For interacting with Claude AI
- @modelcontextprotocol/sdk: Model Context Protocol SDK
- @anaisbetts/mcp-youtube: YouTube tools for MCP
- spawn-rx: For spawning processes
', '"{\"Agent Frameworks\",\"Function Calling\",\"Protocol Implementations\"]}', '{"is_mcp":"YES","justification":"The repository description explicitly mentions Model Context Protocol (MCP) and interacting with Claude AI using MCP for tool usage with YouTube context. It also uses @modelcontextprotocol/sdk.","categories":["AI Model Integration","Function Calling","Protocol Implementations"],"analysis":{"Architecture and Design Patterns":"The architecture consists of a client interacting with an MCP server. The client leverages the Anthropic API to send prompts and tool information. The system appears to use a command-line interface for user interaction. The design pattern employed seems to be a client-server model, with the client initiating requests and the server providing responses and tools.","Implementation Details and Key Features":"The client is implemented using Node.js and the Bun runtime. Key features include initializing an Anthropic client, starting an MCP YouTube server process, connecting to the MCP server, retrieving available tools, and converting these tools into Anthropic's format.  It allows Claude to access and utilize tools provided via the MCP.","Integration Approaches and Protocols":"The primary integration approach revolves around the Model Context Protocol (MCP). The client integrates with Anthropic's Claude AI through its SDK and communicates with a separate MCP server. The protocol facilitates the use of external tools by the AI model, specifically designed for YouTube context in this case.","Technical Stack and Dependencies":"The technical stack includes Node.js (v18+), Bun runtime, and TypeScript. Key dependencies are @anthropic-ai/sdk for interacting with Claude, @modelcontextprotocol/sdk for MCP functionality, @anaisbetts/mcp-youtube for YouTube tools, and spawn-rx for process management. The project uses Bun for package management, running scripts, and type checking.","Best Practices and Coding Standards":"The repository includes scripts for running tests (bun test) and type checking (bun typecheck), suggesting a focus on code quality. The project uses standard tools for development (e.g., git for version control, npm/bun for dependency management). The documentation is clear and concise, providing instructions for installation and usage.","Performance Considerations":"Performance considerations aren't explicitly addressed, but the use of Bun runtime might suggest an intent to improve startup time and overall execution speed. The client's interaction with the MCP server and Claude API introduces network latency. The efficiency of tool execution on the MCP server is also a factor for overall performance."}}', '2025-03-10 21:54:07+00', 'mcp-client-dumb', 'true', 'true'), ('945152231', 'open-mcp-client', 'CopilotKit/open-mcp-client', 'https://github.com/CopilotKit/open-mcp-client', null, '2025-03-08 19:22:42+00', '2025-03-10 18:01:06+00', 'TypeScript', '579', 'https://github.com/user-attachments/assets/f72e1f7d-3c84-4429-a465-23dff3d3bd63


# Getting Started

## Set Up Environment Variables:

```sh
touch .env
```

Add the following inside `.env` at the root:

```sh
LANGSMITH_API_KEY=lsv2_...
```

Next, create another `.env` file inside the `agent` folder:

```sh
cd agent
touch .env
```

Add the following inside `agent/.env`:

```sh
OPENAI_API_KEY=sk-...
LANGSMITH_API_KEY=lsv2_...
```

## Development

We recommend running the **frontend and agent separately** in different terminals to debug errors and logs:

```bash
# Terminal 1 - Frontend
pnpm run dev-frontend

# Terminal 2 - Agent
pnpm run dev-agent
```

Alternatively, you can run both services together with:

```bash
pnpm run dev
```

Then, open [http://localhost:3000](http://localhost:3000) in your browser.

## Architecture

The codebase is split into two main parts:

1. `/agent` **folder** – A LangGraph agent that connects to MCP servers and calls their tools.
2. `/app` **folder** – A frontend application using CopilotKit for UI and state synchronization.
', '"{\"Agent Frameworks\",\"Function Calling\",\"API Frameworks\"]}', '{"is_mcp":"YES","justification":"The repository name 'open-mcp-client' and the description of the agent connecting to MCP servers indicate it implements or relates to Model Context Protocol (MCP) specifications. It also utilizes function calling via LangGraph.","categories":["Agent Frameworks","Function Calling","Protocol Implementations"],"analysis":{"Architecture and Design Patterns":"The architecture is divided into two primary components: a LangGraph agent residing in the `/agent` directory and a frontend application located in the `/app` directory. This separation allows for independent development and debugging of the agent and the UI. The agent interacts with MCP servers, while the frontend leverages CopilotKit for UI management.","Implementation Details and Key Features":"The agent is built using LangGraph, suggesting a graph-based approach to managing agent workflows and interactions with tools offered by MCP servers. The frontend utilizes CopilotKit, implying features like state synchronization and UI components tailored for agent interaction. Environment variables manage API keys for OpenAI and LangSmith.","Integration Approaches and Protocols":"The repository integrates with MCP servers through a defined protocol, likely involving API calls to access tools and retrieve context. The LangGraph agent manages the interaction flow, potentially handling authentication, request formatting, and response parsing. The specific protocol details are not explicitly provided but are implied through server interaction.","Technical Stack and Dependencies":"The technical stack includes LangGraph for agent development, CopilotKit for the frontend, and potentially OpenAI for language model integration. Dependencies are managed using `pnpm`, as indicated by the `pnpm run dev` commands. The agent likely relies on standard HTTP libraries for communication with MCP servers. Environment variables store keys.","Best Practices and Coding Standards":"The project promotes separation of concerns by dividing the codebase into distinct agent and frontend components. Using environment variables for sensitive information like API keys is a good practice. The provided development commands encourage separate execution for easier debugging. No code samples are available for assessment.","Performance Considerations":"Performance considerations are not explicitly addressed in the provided documentation. However, the use of LangGraph might enable optimization of agent workflows, potentially leading to faster response times. The performance of the agent is dependent on the MCP server's response time and the efficiency of the LangGraph implementation."}}', '2025-03-10 21:26:16+00', 'open-mcp-client', 'true', 'true'), ('945235930', 'mcp4go', 'mcp4go/mcp4go', 'https://github.com/mcp4go/mcp4go', 'A comprehensive Go SDK for the Model Context Protocol (MCP) - simplifying AI application development by abstracting away protocol complexities.', '2025-03-09 00:46:04+00', '2025-03-10 17:01:49+00', 'Go', '3', '<p align="center">
<a href="https://github.com/mcp4go/mcp4go/actions"><img src="https://github.com/mcp4go/mcp4go/workflows/Go/badge.svg?v=1231" alt="Build Status"></a>
<a href="https://pkg.go.dev/github.com/mcp4go/mcp4go"><img src="https://pkg.go.dev/badge/github.com/mcp4go/mcp4go?v=1231" alt="GoDoc"></a>
<a href="https://codecov.io/gh/mcp4go/mcp4go"><img src="https://codecov.io/gh/mcp4go/mcp4go/master/graph/badge.svg?v=1231" alt="codeCov"></a>
<a href="https://goreportcard.com/report/github.com/mcp4go/mcp4go"><img src="https://goreportcard.com/badge/github.com/mcp4go/mcp4go?v=1231" alt="Go Report Card"></a>
<a href="https://github.com/mcp4go/mcp4go/blob/main/LICENSE"><img src="https://img.shields.io/github/license/mcp4go/mcp4go?v=1231" alt="License"></a>
<a href="https://github.com/avelino/awesome-go"><img src="https://awesome.re/mentioned-badge.svg?v=1231" alt="Awesome Go"></a>
</p>

# MCP4Go

MCP4Go is a Go implementation of the Model Context Protocol (MCP), designed to simplify the development of AI applications by abstracting away protocol complexities.

## Features

- Complete MCP protocol implementation in pure Go
- High-level abstractions for common MCP resources
- Pluggable architecture for custom extensions
- Comprehensive documentation and examples
- Production-ready with robust error handling

## Installation

MCP4Go requires Go 1.18 or later. Install it using Go modules:

```bash
go get github.com/mcp4go/mcp4go
```


## Protocol Implementation
MCP4Go provides a complete implementation of the Model Context Protocol with support for:
- JSON-RPC communication
- Resource lifecycle management
- Prompt engineering
- Tool definitions and invocations
- Sampling parameters
- Logging and diagnostics

## License
This project is licensed under the MIT License
## Contributing
Contributions are welcome! Please see our Contributing Guide for more information.
', '"{\"Protocol Implementations\",\"AI Model Integration\",\"Function Calling\"]}', '{"is_mcp":"YES","justification":"The repository explicitly states it's a Go SDK for the Model Context Protocol (MCP), aiming to simplify AI application development by abstracting protocol complexities.","categories":["Protocol Implementations","AI Model Integration","Function Calling"],"analysis":{"Architecture and Design Patterns":"The repository implements the Model Context Protocol (MCP) using a Go SDK. It features a pluggable architecture designed to accommodate custom extensions, suggesting a modular and extensible design. The architecture abstracts the complexities of the underlying protocol, providing a higher-level interface for developers to interact with MCP functionalities.","Implementation Details and Key Features":"MCP4Go provides a comprehensive implementation of the Model Context Protocol, including JSON-RPC communication and resource lifecycle management. Key features include support for prompt engineering, tool definitions and invocations, sampling parameters, and logging and diagnostics. The implementation uses Go modules for dependency management and offers robust error handling.","Integration Approaches and Protocols":"The repository focuses on integrating AI models through the Model Context Protocol (MCP). It utilizes JSON-RPC for communication between components. The SDK provides abstractions for defining and invoking tools, managing resources, and configuring sampling parameters, streamlining the integration process for AI applications.","Technical Stack and Dependencies":"The primary technical stack consists of Go (version 1.18 or later). It relies on Go modules for managing dependencies. The project utilizes libraries for JSON-RPC communication. The presence of build status badges, code coverage, and Go Report Card suggests a focus on code quality and maintainability.","Best Practices and Coding Standards":"The repository includes a contributing guide, indicating an emphasis on community contributions and standardized development practices. The use of linters and code formatting tools (as suggested by the Go Report Card) helps ensure code consistency and adherence to best practices. Comprehensive documentation is also provided.","Performance Considerations":"The performance considerations are not explicitly stated but can be inferred. The use of Go suggests an emphasis on concurrency and efficient resource utilization. Production-ready error handling and comprehensive logging and diagnostics can contribute to the performance and stability of applications using the SDK. "}}', '2025-03-10 21:26:16+00', 'mcp-go-sdk', 'true', 'true'), ('945567855', 'gmail-mcp-client-server', 'karimdabbouz/gmail-mcp-client-server', 'https://github.com/karimdabbouz/gmail-mcp-client-server', 'MCP client and server to hook up Claude to Gmail.', '2025-03-09 18:13:11+00', '2025-03-10 17:32:14+00', 'Python', '0', '


## Important: Authenticating with Gmail

Manual OAuth authentication via the browser is required to work with Gmail. To do so, run server.py once as a standalone script with the credentials.json file next to the server.py script. It will then ask you to authenticate using your browser. After authenticating, the session is saved as token.pickle in the root of this project. You can then use this pickle file to start the client and server via the client.py file.

Information on authentication with Gmail and getting the credentials.json file: https://developers.google.com/gmail/api/quickstart/python', '"{\"Function Calling\",\"Protocol Implementations\",\"AI Model Integration\"]}', '{"is_mcp":"YES","justification":"The repository description explicitly states \"MCP client and server\" and its purpose is to connect Claude to Gmail, which aligns with the MCP concept of connecting models with external tools.","categories":["Function Calling","AI Model Integration","Protocol Implementations"],"analysis":{"Architecture and Design Patterns":"The repository follows a client-server architecture where the server likely interacts with the Gmail API, and the client interfaces with the AI model (Claude). The client-server pattern allows for clear separation of concerns and scalable interaction between the AI model and the external service. This architecture facilitates interaction of Large Language Models with external services.","Implementation Details and Key Features":"The core feature is integrating Claude with Gmail. The server handles Gmail API interactions, while the client manages communication with Claude. A key implementation detail is the use of OAuth 2.0 for authentication. The storage of tokens in pickle files suggests a simple persistence mechanism for managing user sessions, but it may raise security concerns.","Integration Approaches and Protocols":"The repository employs the Gmail API to interact with Gmail. OAuth 2.0 is used for authentication, as evidenced by the documentation's reference to obtaining `credentials.json` and the creation of `token.pickle`. The integration likely involves sending and receiving email data between Claude and Gmail via API calls.","Technical Stack and Dependencies":"The repository is written in Python and depends on the Gmail API client library. The use of pickle for token storage suggests a reliance on Python's built-in serialization capabilities. The documentation highlights the need for `credentials.json`, indicating a dependency on Google Cloud Platform or a similar service for API access.","Best Practices and Coding Standards":"The documentation points to Google's Gmail API quickstart guide, indicating an adherence to Google's recommended authentication practices. However, storing tokens in pickle files, while convenient, is not generally considered a secure practice for production environments. Other coding standards are not ascertainable without access to the codebase.","Performance Considerations":"Performance considerations include API rate limits imposed by the Gmail API, especially with the client-server architecture enabling multiple requests. Efficient handling of API requests and data transfer is crucial. OAuth token refresh mechanisms should be handled correctly to maintain continuous operation. The serialization and deserialization of data could also impact performance."}}', '2025-03-10 21:26:16+00', 'gmail-mcp-claude', 'true', 'true'), ('945694930', 'mcp-client-server', 'willccbb/mcp-client-server', 'https://github.com/willccbb/mcp-client-server', 'An MCP Server that's also an MCP Client. Useful for letting Claude develop and test MCPs without needing to reset the application.', '2025-03-10 01:22:06+00', '2025-03-10 17:35:23+00', 'TypeScript', '98', '# MCP Test Client

An MCP middleware that acts as both a server (to Claude) and a client (to servers under test) for testing MCP servers during development.

## Architecture

The MCP Test Client has a dual role:
- It's a **server** registered with Claude that exposes tools for testing
- It's a **client** that connects to and tests other MCP servers

```
┌─────────────┐          ┌───────────────────┐          ┌────────────────┐
│             │  Tools   │                   │  Client  │                │
│   Claude    │─────────>│  MCP Test Client  │─────────>│  Server Under  │
│             │          │                   │          │     Test       │
└─────────────┘          └───────────────────┘          └────────────────┘
```

This architecture lets you test MCP servers without registering them directly with Claude.

## Features

- Deploy MCP servers to test environments
- Call individual tools with custom arguments
- Run automated test suites
- View server logs
- Test servers before formal registration with Claude

## Implementation

The MCP Test Client is implemented with:

- **Process Management**: Spawns and manages MCP server processes
- **MCP SDK Client**: Uses the official MCP SDK to communicate with servers
- **Custom Transport**: Implements a custom transport for stdio communication
- **Test Execution**: Runs tests and validates responses
- **CLI Interface**: Provides an interactive testing interface

The current implementation is Phase 1 of the design plan, with future enhancements planned for Phases 2 and 3.

## Installation

```bash
# Install dependencies
npm install

# Build the TypeScript project
npm run build
```

## Usage

### As an MCP Server

The MCP Test Client is registered with Claude via the `claude-mcp-local` script. You can use the following tools:

1. Deploy a server:
```typescript
mcp__mcp-test__mcp_test_deploy_server({
  name: "my-server",
  source_path: "/path/to/server",
  env_vars: {
    "API_KEY": "${API_KEY}"
  }
})
```

2. Call a tool on a deployed server:
```typescript
mcp__mcp-test__mcp_test_call_tool({
  server_name: "my-server",
  tool_name: "tool_name",
  arguments: {
    // Tool-specific arguments
  }
})
```

3. Run tests against a server:
```typescript
mcp__mcp-test__mcp_test_run_tests({
  server_name: "my-server"
})
```

4. View server logs:
```typescript
mcp__mcp-test__mcp_test_get_logs({
  server_name: "my-server",
  lines: 100
})
```

5. List deployed servers:
```typescript
mcp__mcp-test__mcp_test_list_servers({})
```

6. Stop a server:
```typescript
mcp__mcp-test__mcp_test_stop_server({
  server_name: "my-server"
})
```

### As a CLI Tool

Run the CLI interface for testing:

```bash
# Use npm script
npm run test

# Or run directly
node dist/test-runner.js
```

This provides an interactive menu for deploying, testing, and managing MCP servers.

## Development Workflow

The MCP Test Client supports this workflow:

1. Develop an MCP server in the playground directory
2. Deploy it to the test environment with MCP Test Client
3. Test functionality, call individual tools, and debug issues
4. Fix and iterate until the server works correctly
5. Migrate the server to mcp-servers/ when ready
6. Register with Claude through claude-mcp-local

## Future Enhancements

Planned enhancements include:

- **Phase 2**: Docker-based container management, comprehensive test suites
- **Phase 3**: Migration tools, more advanced test validation

See `notes/mcp_test_client_design.md` for the complete design document.
', '"{\"Protocol Implementations\",\"Developer Tooling\",\"AI Testing Frameworks\"]}', '{"is_mcp":"YES","justification":"The repository explicitly implements an MCP server and client for testing purposes. It interacts with Claude using MCP, deploys test servers, calls tools, and runs tests, directly relating to MCP specifications.","categories":["AI Model Integration","API Frameworks","Developer Tooling"],"analysis":{"Architecture and Design Patterns":"The repository adopts a dual role as both an MCP server and client, designed for testing MCP servers during development. It utilizes a clear architecture with distinct components for process management, client communication, and test execution. The design includes modularity to easily manage interactions and future enhancements, with phased implementation planned.","Implementation Details and Key Features":"Implemented using process management for spawning servers, an MCP SDK client for communication, and custom transport over stdio. Key features include the ability to deploy servers, call tools with custom arguments, run test suites, and view server logs. The interactive CLI interface offers a convenient way to manage and test MCP servers.","Integration Approaches and Protocols":"The repository integrates with Claude using the MCP protocol, enabling deployment and testing of servers. It employs a custom transport mechanism for stdio communication. Integration points involve deploying servers, calling tools, and running tests, as demonstrated in the provided code snippets for interacting with the test client.","Technical Stack and Dependencies":"The technical stack includes TypeScript, indicated by the `npm run build` command, along with `npm` for managing dependencies. The usage of the official MCP SDK is a core dependency. The repository utilizes a custom transport mechanism implying further internal dependencies related to stdio communication handling.","Best Practices and Coding Standards":"The presence of a design document (`notes/mcp_test_client_design.md`) indicates some attention to design and planning. The modular architecture and phased implementation suggest an intention to follow good coding practices. The TypeScript implementation implies the use of static typing for maintainability and reducing errors.","Performance Considerations":"The use of stdio for communication might introduce performance limitations compared to other transport methods. Process management for server spawning could also impact performance depending on the number and complexity of servers. Future enhancements in Docker-based container management may address some performance concerns by improving resource utilization and isolation."}}', '2025-03-10 21:28:27+00', 'mcp-client-server-dev', 'true', 'true');